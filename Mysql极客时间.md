# 02 | 日志系统：一条SQL更新语句是如何执行的？





你执行语句前要先连接数据库，这是连接器的工作。前面我们说过，在一个表上有更新的时候，跟这个表有关的查询缓存会失效，所以这条语句就会把表 T 上所有缓存结果都清空。这也就是我们一般不建议使用查询缓存的原因。接下来，分析器会通过词法和语法解析知道这是一条更新语句。优化器决定要使用 ID 这个索引。然后，执行器负责具体执行，找到这一行，然后更新。与查询流程不一样的是，更新流程还涉及两个重要的日志模块，它们正是我们今天要讨论的主角：redo log（重做日志）和 binlog（归档日志）。

![img](https://static001.geekbang.org/resource/image/0d/d9/0d2070e8f84c4801adbfa03bda1f98d9.png)

## 重要的日志模块：redo log



InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么这块“粉板”总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。

![image-20211013201106503](E:\TyporaPic\image-20211013201106503.png)

write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。





有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 crash-safe。





## 重要的日志模块：binlog



binlog在Server层

我想你肯定会问，为什么会有两份日志呢？

因为最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用另外一套日志系统——也就是 redo log 来实现 crash-safe 能力。



这两种日志有以下三点不同。

1. **redo log是InnoDB引擎特有的**，*binlog 是 MySQL 的 Server 层*实现的，所有引擎都可以使用。
2. **redo log是物理日志**，纪录的是 “在某个数据也上做了什么修改”;bin log是逻辑日志，纪录的是；**binlog是逻辑日志**，纪录的是语句的原始逻辑，例如“给 ID=2 这一行的 c 字段加 1 ”。（Binlog有两种模式，statement 格式的话是记sql语句， row格式会记录行的内容，记两条，更新前和更新后都有。）
3. redo log是循环写的 而binlog 是追加写的，“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。



执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程。



我们再来看执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程。 （给 ID=2 这一行的 c 字段加 1）



1. 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。
2. 执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入新的一行纪录
3. 引擎将新的记录更新到内存中，同时将更新操作写入到redo log里面，此**时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。**
4. **执行器生成这个操作的Binlog,并把Binlog写入到磁盘**
5. 执行器调用引擎的事务提交接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。



图中**浅色框表示是在 InnoDB 内部执行的**，**深色框表示是在执行器中执行**的。

![img](https://static001.geekbang.org/resource/image/2e/be/2e5bff4910ec189fe1ee6e2ecc7b4bbe.png)



## 两阶段提交



## 为什么必须有两阶段提交呢？

这是为了让两份日志之间的逻辑一致



要说明这个问题，我们得从文章开头的那个问题说起：怎样让数据库恢复到半个月内任意一秒的状态？

binlog 会记录所有的逻辑操作，并且是采用“追加写”的形式。如果你的 DBA 承诺说半个月内可以恢复，那么备份系统中一定会保存最近半个月的所有 binlog，同时系统会定期做整库备份。这里的“定期”取决于系统的重要性，可以是一天一备，也可以是一周一备。



当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做：

- 首先，**找到最近的一次全量备份**，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库；
- 然后，从备份的时间点开始，**将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻**



这样你的临时库就跟误删之前的线上库一样了，然后你可以把表数据从临时库取出来，按需要恢复到线上库去。

好了，说完了数据恢复过程，我们回来说说，为什么日志需要“两阶段提交”。这里不妨用反证法来进行解释。

由于 redo log 和 binlog 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redo log 再写 binlog，或者采用反过来的顺序。我们看看这两种方式会有什么问题。



仍然用前面的 update 语句来做例子。假设当前 ID=2 的行，字段 c 的值是 0，再假设执行 update 语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了 crash，会出现什么情况呢？



1. 先写 redo log 后写 binlog。假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。
2. 先写 binlog 后写 redo log。如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把 c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。





### 追问 1：MySQL 怎么知道 binlog 是完整的?

回答：

一个事务的 binlog 是有完整格式的：

- statement 格式的 binlog，最后会有 COMMIT；
- row 格式的 binlog，最后会有一个 XID event。



### 追问 2：redo log 和 binlog 是怎么关联起来的?

回答：它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log：

- 如果碰到既有prepare 又有commit的redo log ,就直接提交
- 如果碰到只有 prepare而没有 commit的redo log 就拿着XID去binlog找对应的事务



### 追问 3：处于 prepare 阶段的 redo log 加上完整 binlog，重启就能恢复，MySQL 为什么要这么设计

其实，这个问题还是跟我们在反证法中说到的**数据与备份的一致性有关**。在时刻 B，也就是 binlog 写完以后 MySQL 发生崩溃，这时候 binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。

所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性。



### 追问 4：如果这样的话，为什么还要两阶段提交呢？干脆先 redo log 写完，再写 binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？



对于 InnoDB 引擎来说，如果 redo log 提交完成了，事务就不能回滚（如果这还允许回滚，就可能覆盖掉别的事务的更新）。而如果 redo log 直接提交，然后 binlog 写入的时候失败，InnoDB 又回滚不了，数据和 binlog 日志又不一致了。**两阶段提交就是为了给所有人一个机会，当每个人都说“我 ok”的时候，再一起提交**。由Binlog来通知InnoDB引擎来执行prepare，commit或者rollback的步骤



### 追问 5：不引入两个日志，也就没有两阶段提交的必要了。只用 binlog 来支持崩溃恢复，又能支持归档，不就可以了？





# 







# 23 | MySQL是怎么保证数据不丢的？ redo log和binlog 是如何保证完整的？

只要 redo log 和 binlog 保证持久化到磁盘，就能确保 MySQL 异常重启后，数据可以恢复。



### binlog和 redolog的写入流程

### binlog 的写入机制





其实，binlog 的写入逻辑比较简单：事务执行过程中，**先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中**。



一个事物的binlog是不能被拆开的，因此无论这个事务多大，也要确保一次性写入。

系统给 binlog cache 分配了一片内存，每个线程一个，**参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小**。如果超过了这个参数规定的大小，就要暂存到磁盘。

事务提交的时候，**执行器把 binlog cache 里的完整事务写入到 binlog 中，并清空 binlog cache**。

![img](https://static001.geekbang.org/resource/image/9e/3e/9ed86644d5f39efb0efec595abb92e3e.png)

可以看到，每个线程有自己 binlog cache，但是共用同一份 binlog 文件（binlog  file）。

- 图中的 write，指的就是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快。
- 图中的 fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为 fsync 才占磁盘的 IOPS。



### binlog 持久化到磁盘的时机

**write 和 fsync 的时机**，是由参数 sync_binlog 控制的：

1. sync_binlog=0的时候，表示每次提交事务都只write，不fsync
2. sync_binlog=1 的时候，表示每次提交事务都会执行 fsync；
3. sync_binlog=N(N>1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。

因此，在出现 IO 瓶颈的场景里，将 sync_binlog 设置成一个比较大的值，可以提升性能。在实际的业务场景中，考虑到丢失日志量的可控性，一般不建议将这个参数设成 0，比较常见的是将其设置为 100~1000 中的某个数值。

但是，将 sync_binlog 设置为 N，对应的风险是：如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志。

0 每次事务提交只wtire

1 每次事务提交都fsync

N 每次事务提交先write 累计N个之后再fsync



### redo log 的写入机制

然后就有同学问了，redo log buffer 里面的内容，是不是每次生成后都要直接持久化到磁盘呢？答案是，不需要。



### redo log buffer 里面的内容，是不是每次生成后都要直接持久化到磁盘呢？



不需要

如果事务执行期间，MySQL 发生异常重启，那这部分日志就丢了。由于事务并没有提交，所以这时日志丢了也不会有损失。



### 那么，另外一个问题是，事务还没提交的时候，redo log buffer 中的部分日志有没有可能被持久化到磁盘呢？



答案是，确实会有。

这个问题，要从 redo log 可能存在的三种状态说起。这三种状态，对应的就是图 2 中的三个颜色块。

![img](https://static001.geekbang.org/resource/image/9d/d4/9d057f61d3962407f413deebc80526d4.png)



这三种状态分别是：

1.存在 redo log buffer中，物理上是在Mysql进程内存中，就是图中红色部分

2.写到磁盘(write),但是没有持久化(fsync)物理上是在文件系统的 page cache 里面，也就是图中的黄色部分；

3.持久化到磁盘，对应的是 hard disk，也就是图中的绿色部分。



日志写到 redo log buffer 是很快的，wirte 到 page cache 也差不多，但是持久化到磁盘的速度就慢多了。





redo log写入磁盘策略，InnoDB 提供了 innodb_flush_log_at_trx_commit 参数，它有三种可能取值：

1.设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 ;

2.设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘；

3.设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache。



**0- redo log buffer **

**1- 持久化到磁盘 **

**2-写到 page cache**



InnoDB有一个后台线程，每隔1s,就会把redo log buffer中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。



注意，事务执行中间过程的 redo log 也是直接写在 redo log buffer 中的，这些 redo log 也会被后台线程一起持久化到磁盘。**也就是说，一个没有提交的事务的 redo log，也是可能已经持久化到磁盘的。**



### 除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的 redo log 写入到磁盘中。

1.一种是，redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程会主动写盘。注意，**由于这个事务并没有提交，所以这个写盘动作只是 write，而没有调用 fsync**，也就是只留在了文件系统的 page cache。

2**.另一种是，并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁盘**。假设一个事务 A 执行到一半，已经写了一些 redo log 到 buffer 中，这时候有另外一个线程的事务 B 提交，如果 innodb_flush_log_at_trx_commit 设置的是 1，那么按照这个参数的逻辑，事务 B 要把 redo log buffer 里的日志全部持久化到磁盘。这时候，就会带上事务 A 在 redo log buffer 里的日志一起持久化到磁盘。



时序上 redo log 先 prepare， 再写 binlog，最后再把 redo log commit。

如果把 innodb_flush_log_at_trx_commit 设置成 1，那么 redo log 在 prepare 阶段就要持久化一次，因为有一个崩溃恢复逻辑是要依赖于 prepare 的 redo log，再加上 binlog 来恢复的。

每秒一次后台轮询刷盘，再加上崩溃恢复这个逻辑，InnoDB 就认为 redo log 在 commit 的时候就不需要 fsync 了，只会 write 到文件系统的 page cache 中就够了。



### 什么是双1配置

通常我们说 MySQL 的“双 1”配置，指的就是 **sync_binlog 和 innodb_flush_log_at_trx_commit 都设置成 1**。也就是说，一个**事务完整提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog。**





这时候，你可能有一个疑问，这意味着我从 MySQL 看到的 TPS 是每秒两万的话，每秒就会写四万次磁盘。但是，我用工具测试出来，磁盘能力也就两万左右，怎么能实现两万的 TPS？



### 组提交机制

日志逻辑序列号（log sequence number，LSN）的概念。**LSN 是单调递增的，用来对应 redo log 的一个个写入点**。**每次写入长度为 length 的 redo log， LSN 的值就会加上 length。**



LSN 也会写到 InnoDB 的数据页中，来确保数据页不会被多次执行重复的 redo log。关于 LSN 和 redo log、checkpoint 的关系，我会在后面的文章中详细展开。



图 3 所示，是三个并发事务 (trx1, trx2, trx3) 在 prepare 阶段，都写完 redo log buffer，持久化到磁盘的过程，对应的 LSN 分别是 50、120 和 160。

![img](https://static001.geekbang.org/resource/image/93/cc/933fdc052c6339de2aa3bf3f65b188cc.png)

从图中可以看到

1.trx1 是第一个到达的，会被选为这组的 leader；

2.等 trx1 要开始写盘的时候，这个组里面已经有了三个事务，这时候 LSN 也变成了 160；

3.trx1 去写盘的时候，带的就是 LSN=160，因此等 trx1 返回时，所有 LSN 小于等于 160 的 redo log，都已经被持久化到磁盘；

4.这时候 trx2 和 trx3 就可以直接返回了。

在并发更新场景下，第一个事务写完 redo log buffer 以后，接下来这个 fsync 越晚调用，组员可能越多，节约 IOPS 的效果就越好。为了让一次 fsync 带的组员更多，MySQL 有一个很有趣的优化：拖时间。在介绍两阶段提交的时候，我曾经给你画了一个图，现在我把它截过来。

![img](https://static001.geekbang.org/resource/image/98/51/98b3b4ff7b36d6d72e38029b86870551.png)





图中，我把“写 binlog”当成一个动作。但实际上，写 binlog 是分成两步的：

1. 先把 binlog 从 binlog cache 中写到磁盘上的 binlog 文件；

2. 调用 fsync 持久化。



MySQL 为了让组提交的效果更好，把 redo log 做 fsync 的时间拖到了步骤 1 之后。也就是说，上面的图变成了这

![img](https://static001.geekbang.org/resource/image/5a/28/5ae7d074c34bc5bd55c82781de670c28.png)

这么一来，binlog 也可以组提交了。在执行图 5 中第 4 步把 binlog fsync 到磁盘时，如果有多个事务的 binlog 已经写完了，也是一起持久化的，这样也可以减少 IOPS 的消耗。

不过通常情况下第 3 步执行得会很快，所以 binlog 的 write 和 fsync 间的间隔时间短，导致能集合到一起持久化的 binlog 比较少，因此 binlog 的组提交的效果通常不如 redo log 的效果那么好。

如果你想提升 binlog 组提交的效果，可以通过设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 来实现。

1. binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync;
2. binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。

这两个条件是或的关系，也就是说只要有一个满足条件就会调用 fsync。所以，当 binlog_group_commit_sync_delay 设置为 0 的时候，binlog_group_commit_sync_no_delay_count 也无效了。



### WAL 机制是减少磁盘写，可是每次提交事务都要写 redo log 和 binlog，这磁盘读写次数也没变少呀？



现在你就能理解了，WAL 机制主要得益于两个方面：

1.redo log 和 binlog 都是顺序写，磁盘的顺序写比随机写速度要快；

2.组提交机制，可以大幅度降低磁盘的 IOPS 消耗。





### 如果你的 MySQL 现在出现了性能瓶颈，而且瓶颈在 IO 上，可以通过哪些方法来提升性能呢？





1.设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，减少 binlog 的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。

2.将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000）。这样做的风险是，主机掉电时会丢 binlog 日志。

3.将 innodb_flush_log_at_trx_commit 设置为 2。这样做的风险是，主机掉电的时候会丢数据。





## redo log与Bin log顺序一致性



**为什么MySQL有binlog，还有redo log?**



这个是因为MySQL体系结构的原因，MySQL是多存储引擎的，不管使用那种存储引擎，都会有binlog，而不一定有redo log，简单的说，binlog是MySQL Server层的，redo log是InnoDB层的。



**事务是如何提交的？事务提交先写binlog还是redo log？如何保证这两部分的日志做到顺序一致性？**

MySQL Binary log在MySQL 5.1版本后推出主要用于主备复制的搭建，我们回顾下MySQL在开启/关闭Binary Log功能时是如何工作的。



MySQL没有开启Binary Log的情况下？



首先看一下什么事 CrashSafe?CrashSafe指MySQL服务器宕机重启后，能够保证：

- 所有已提交的事务的数据仍然存在
- 所有提交事务的数据自动回滚



InnoDB通过Redo Log和Undo Log可以保证以上两点。为了保证严格的CrashSafe,必须要在每隔事务提交的时候将Redo log 写入硬件存储。

这样做会牺牲一些性能，但是可靠性最好，InnoDB提供了一个innodb_flush_log_at_trx_commit系统变量，用户可以根据应用的需求自行调整。



> innodb_flush_log_at_trx_commit = 0|1|2
>
> 0 -每N秒将Redo log buffer的济洛路写入RedoLog 文件，并且将文件刷入磁盘1次。 N由innodb_flush_log_at_timeout控制。
>
> 1 – 每个事务提交时，将记录从Redo Log Buffer写入Redo Log文件，并且将文件刷入硬件存储。
>
> 2 – 每个事务提交时，仅将记录从Redo Log Buffer写入Redo Log文件。Redo Log何时刷入硬件存储由操作系统和innodb_flush_log_at_timeout决定。这个选项可以保证在MySQL宕机，而操作系统正常工作时，数据的完整性。

通过redo log 将所有已经在存储疫情内部提交事务 应用redo log回复，所有已经prepare但是没有commit的transactions将会应用 undolog 做rollback,然后客户端连接时就能看到已经提交的数据存在DB内，为提交被回滚地数需要重新执行



### MySQL开启Binary log的情况下？ 

MySQL**为了保证 master和slave的数据一致性，就必须保证 binlog和InnoDB redo log的一致性**

（因为备库通过二进制日志重放主库提交的事务，而主库binlog写入在commit之前，如果写完binlog主库crash，再次启动时会回滚事务。但此时从库已经执行，则会造成主备数据不一致）

所以在开启Binlog后，如何保证 binlog和InnoDB redolog日志一致性呢？



为此MYSQL引入了 二阶段提交（2PC）

MySQL内部会自动将普通事务当做一个XA事务（内部分布式事物）来处理：

- 自动为每个事务分配一个唯一的ID（XID）
- **COMMIT会被自动的分成Prepare和Commit两个阶段**
- Binlog会被当做事务协调者（Transaction Coordinator）Binlog Event会被当做协调者日志。



Binlog在2PC中充当了事务的协调者（Transaction Coordinator）。由Binlog来通知InnoDB引擎来执行prepare，commit或者rollback的步骤。事务提交的整个过程如下：



![img](http://www.ywnds.com/wp-content/uploads/2016/08/2016082210501810.png)



事务的提交主要分为两个主要步骤：

1.准备阶段(Stroage Engine (InnoDB) Transaction Prepare Phase)

此时SQL已经成功执行，并生成xid信息以及redo 和undo log内存日志，然后调用prepare方法完成第一阶段,prepare方法实际上什么也没做 将事务状态设置为TRX_PREPARED,并将redo log刷磁盘

2.提交阶段(Storage Engine（InnoDB）Commit Phase)

2.1 记录协调者日志，即Binlog日志。

如果事务设计所有存储引擎的prepare都执行成功，则调用TC_LOG_BINLOG::log_xid方法将SQL语句写到binlog （write()将binary log内存日志数据写入文件系统缓存，fsync()将binary log文件系统缓存日志数据永久写入磁盘）,此时，事务已经铁定要提交了。否则，调用ha_rollback_trans方法回滚事务，而SQL语句实际上也不会写到binlog。

2.2 告诉引擎做commit。

最后，调用引擎的commit完成事务的提交。会清除undo信息(UNDO 链)，刷redo日志，将事务设为TRX_NOT_STARTED状态。

> PS：记录Binlog是在InnoDB引擎Prepare（即Redo Log写入磁盘）之后，这点至关重要。



事务的两阶段提交协议保证了无论在任何情况下，事务要么同时存在于存储引擎和binlog中，要么两个里面都不存在，这就保证了主库与从库之间数据的一致性。



**为了保障主从复制安全，故障恢复是如何做的？**

开启Binary log的MySQK在crash recovery时，MySQL在prepare阶段生成xid，然后再commit阶段写入到binlog中。**在进行恢复时，事务要提交还是回滚，是有Binlog来决定的**



- 事务的Xid_log_event存在，就要提交
- 事务的Xid_log_event不存在，就要回滚。

恢复的过程非常简单



- 从binlog中读出所有的Xid_log_event
- 告诉InnoDB提交这些XID的事务
- InnoDB回滚其他的事务



xid是binlog与redo log共同的数据字段，崩溃恢复的时候，会按顺序扫描redo log

- 如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；
- 如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。









总结起来说就是如果一个事务在prepare阶段中落盘成功，并在MySQL Server层中的binlog也写入成功，那这个事务必定commit成功。





**为什么需要保证二进制日志的写入顺序和InnoDB层事务提交顺序一致性呢？**



上面提到单个事务的二阶段提交过程，能够抱枕存储引擎和binarylog日志保持一致，但是**在并发情况下怎么保证 InnoDB层事务日志和MYSQL二进制日志的提价顺序一致？**

当多个事务并发提交的情况，如果Binary Log和存储引擎顺序不一致会造成什么影响？

![img](http://www.ywnds.com/wp-content/uploads/2016/08/201608221053511.png)



如上图，事务按照T1,T2,T3顺序开始执行，将**二进制日志(T1T2T3顺序)写入日志文件系统缓冲**，调用fsync()进行一次group commit将日志文件永久写入磁盘，**但是存储引擎提交的顺序为T2 T3 T1**.



这时候我们做了一个热备份的操作，有多种方式进行数据库的热备份，比如：XtraBackup等。这时候就会发生错误。会发生什么错误，我们需要先了解一下 XtraBackup 等热备工具的备份原理。



> **XtraBackup备份原理：**直接拷贝数据库文件，并且记录下当前二进制日志中已经提交的最后一个事务标记。在新的数据库实例上完成 recovery 操作。

那么事务T1在slave机器restore MySQL数据库的时候发现**未在**存储引擎内提交，T1事务被roll 　了解完备份原理之后，我们就可以想到上述情况下做热备会出现什么情况。因为 T2、T3 已经提交，所以备份的时候会记录下 T3 是最后一个提交的事务，会认为 T3 之前的事务都是已经提交的，由于是直接拷贝数据库文件，可以看到 T1 事务的数据还没有提交到存储引擎层，所以备份数据中还并没有 T1 的数据。如果新的数据库是用来做主从复制的话，change master to 会指向二进制日志中 T3 的位置，从 T3 事务开始往后进行复制，这样一来 T1 事务的数据就这样没了。产生这个问题的主要原因就是：**事务写入二进制日志的顺序与事务在存储引擎层提交的顺序不一致**。



为了解决这个问题，MySQL 引入了 `prepare_commit_mutext` 的机制，当事务提交的时候，需要先获得 `prepare_commit_mutext` 这个锁。有了这个锁就可以保证事务写入二进制日志的顺序与事务在存储引擎层提交的顺序一致。

![img](http://img.blog.itpub.net/blog/attachment/201601/13/28218939_1452655689jUh1.png?x-oss-process=style/bb)



**图3 通过prepare_commit_mutex保证存储引擎和二进制日志顺序提交顺序一致**



- InnoDB prepare （持有prepare_commit_mutex）；
- write/sync Binlog；
- InnoDB commit (写入COMMIT标记后释放prepare_commit_mutex)。





图3可以看出在prepare_commit_mutex，只有当上一个事务commit后释放锁，下一个事务才可以进行prepara操作，并且在每个transaction过程中**Binary log没有fsync()**的调用。



但是这样一来，从图中我们也可以看到，原先是并发的事务，又变成了串行的，效率又变低了。只要是问题，必然存在解决方法。于是三阶段提交就出现了。



## 什么是三阶段提交

三阶段提交，顾名思义有三个阶段： Flush 阶段、sync 阶段、commit 阶段。分别对应的就是二进制日志写内存的阶段、二进制日志刷盘的阶段、事务提交到存储引擎层的阶段。



**binlog组提交的基本思想是，引入队列机制保证innodb commit顺序与binlog落盘顺序一致，并将事务分组，组内的binlog刷盘动作交给一个事务进行，实现组提交目的**





![image-20211015161248333](E:\TyporaPic\image-20211015161248333.png)



每个阶段都有一个队列，每个队列有一个mutex保护,每个阶段都有 leader、follower 两种角色。当一个事务进入三个阶段中的某一个阶段，**如果发现这个阶段中的队列为空，那么这个事务就会成为 leader 的角色**，之后进入同一阶段的事务，发现这个阶段的队列中已经有事务存在了，那就变成 follower 角色。



leader 角色的任务是安排当前阶段队列中的事务按顺序执行，并且带领队列中所有的事务进入下一个阶段.当 leader 带领队列中的事务进入下一阶段的时候，如果发现下一阶段中已经有事务存在（即下一阶段已有 leader 存在），新来的 leader 自动变成 follower 角色。

三阶段提交在**每个阶段都控制了事务的顺序，从而也就控制了事务执行的整体顺序**。同时在第二阶段 Sync阶段 一次将多个事务按照顺序 解决了 `prepare_commit_mutex` 锁导致的问题，事务可以并发的执行。

FLUSH阶段：

- 持有Lock_log mutex [leader持有，follower等待]
- 获取队列中的一组binlog(队列中的所有事务)
- 将binlog buffer到I/O cache
- 通知dump线程dump binlog

SYNC阶段：

- 释放Lock_log mutex，持有Lock_sync mutex[leader持有，follower等待]
- 将一组binlog 落盘(sync动作，最耗时，也是group commit实现了的优化的重点所在)

COMMIT阶段：

- 释放Lock_sync mutex，持有Lock_commit mutex[leader持有，follower等待]
- 遍历队列中的事务，逐一进行innodb commit（这里不用写redo log，在prepare阶段已写）
- 释放Lock_commit mutex
- 唤醒队列中等待的线程



总结：

Flush阶段：将每个事务的二进制文件写入内存

Sync阶段：将内存中的二进制刷新到磁盘，若队列有多个事务，那么仅一次fsync操作就完成了二进制日志的写入，这就是BLGC

Commit阶段：leader根据顺序调用存储引擎层事务提交，由于innodb本就支持group commit，所以解决了因为锁 prepare_commit_mutex 而导致的group commit失效问题。

![img](https:////upload-images.jianshu.io/upload_images/1233356-e00d454c99728a96.png?imageMogr2/auto-orient/strip|imageView2/2/w/934/format/webp)



**这三个阶段的作业是可以同时并发执行的**，当有一组事务在进行commit阶段时，其他新事物可以进行Flush阶段，从而使group commit不断生效。当然group commit的效果由队列中事务的数量决定，若每次队列中仅有一个事务，那么可能效果和之前差不多，甚至会更差。但当提交的事务越多时，group commit的效果越明显，数据库性能的提升也就越大。









# 04 | 深入浅出索引（上）





树可以有二叉，也可以有多叉。多叉树就是每个节点有多个儿子，儿子之间的大小保证从左到右递增。二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上。你可以想象一下一棵 100 万节点的平衡二叉树，树高 20。一次查询可能需要访问 20 个数据块。在机械硬盘时代，从磁盘随机读一个数据块需要 10 ms 左右的寻址时间。也就是说，对于一个 100 万行的表，如果使用二叉树来存储，单独访问一个行可能需要 20 个 10 ms 的时间，这个查询可真够慢的。





为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N 叉”树。这里，“N 叉”树中的“N”取决于数据块的大小。



N 叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。





索引维护B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。以上面这个图为例，如果插入新的行 ID 值为 700，则只需要在 R5 的记录后面插入一个新记录。如果新插入的 ID 值为 400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。而更糟的情况是，如果 R5 所在的数据页已经满了，根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。在这种情况下，性能自然会受影响。除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%。当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程。





> 你可能在一些建表规范里面见到过类似的描述，要求建表语句里一定要有自增主键。当然事无绝对，我们来分析一下哪些场景下应该使用自增主键，而哪些场景下不应该。



自增主键是指自增列上定义的主键，在建表语句中一般是这么定义的： NOT NULL PRIMARY KEY AUTO_INCREMENT。

插入新记录的时候可以不指定 ID 的值，系统会获取当前 ID 最大值加 1 作为下一条记录的 ID 值。

也就是说，自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。





而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。除了考虑性能外，我们还可以从存储空间的角度来看。

假设你的表中确实有一个唯一字段，比如字符串类型的身份证号，那应该用身份证号做主键，还是用自增字段做主键呢？



由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约 20 个字节，而如果用整型做主键，则只要 4 个字节，如果是长整型（bigint）则是 8 个字节。

**显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。**





所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。有没有什么场景适合用业务字段直接做主键的呢？还是有的。

比如，有些业务的场景需求是这样的：

1. 只有一个索引；
2. 该索引必须是唯一索引。

你一定看出来了，这就是典型的 KV 场景。由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。这时候我们就要优先考虑上一段提到的“尽量使用主键查询”原则，直接将这个索引设置为主键，可以避免每次查询需要搜索两棵树。



小结

# 06 | 全局锁和表锁 ：给表加个字段怎么有这么多阻碍？

### 全局锁

顾名思义，全局锁就是对整个数据库实例加锁。**MySQL 提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)**。当你需要**让整个库处于只读状态**的时候，可以使用这个命令，**之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句**。



**全局锁的典型使用场景是，做全库逻辑备份。**也就是把整库每个表都 select 出来存成文本。

以前有一种做法，是通过 FTWRL 确保不会有其他线程对数据库做更新，然后对整个库做备份。注意，在备份过程中整个库完全处于只读状态。

但是让整库都只读，听上去就很危险：

- 如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；
- 如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。

看来加全局锁不太好。但是细想一下，备份为什么要加锁呢？我们来看一下不加锁会有什么问题。



假设你现在要维护“极客时间”的购买系统，关注的是用户账户余额表和用户课程表。

现在发起一个逻辑备份。假设备份期间，有一个用户，他购买了一门课程，业务逻辑里就要扣掉他的余额，然后往已购课程里面加上一门课。

如果时间顺序上是**先备份账户余额表 (u_account)，然后用户购买，然后备份用户课程表 (u_course)**，会怎么样呢？你可以看一下这个图：

![img](https://static001.geekbang.org/resource/image/cb/cd/cbfd4a0bbb1210792064bcea4e49b0cd.png)

​																		图 1 业务和备份状态图

以看到，这个备份结果里，用户 A 的数据状态是“账户余额没扣，但是用户课程表里面已经多了一门课”。如果后面用这个备份来恢复数据的话，用户 A 就发现，自己赚了。作为用户可别觉得这样可真好啊，你可以试想一下：如果备份表的顺序反过来，先备份用户课程表再备份账户余额表，又可能会出现什么结果？	

也就是说，不加锁的话，备份系统备份的得到的库不是一个逻辑时间点，这个视图是逻辑不一致的。

说到视图你肯定想起来了，我们在前面讲事务隔离的时候，其实是有一个方法能够拿到一致性视图的，对吧？

是的，就是在可重复读隔离级别下开启一个事务。

官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数–single-transaction 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。

你一定在疑惑，有了这个功能，为什么还需要 FTWRL 呢？**一致性读是好，但前提是引擎要支持这个隔离级别**。比如，对于 MyISAM 这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用 FTWRL 命令了。

所以，**single-transaction 方法只适用于所有的表使用事务引擎的库。如果有的表使用了不支持事务的引擎，那么备份就只能通过 FTWRL 方法。**这往往是 DBA 要求业务开发人员使用 InnoDB 替代 MyISAM 的原因之一。



你也许会问，既然要全库只读，为什么不使用 set global readonly=true 的方式呢？确实 readonly 方式也可以让全库进入只读状态，但我还是会建议你用 FTWRL 方式，主要有两个原因：

- 一是，在有些系统中，**readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库**。因此，修改 global 变量的方式影响面更大，我不建议你使用。
- 二是，在异常处理机制上有差异。**如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态**，这样会导致整个库长时间处于不可写状态，风险较高。











# 09 | 普通索引和唯一索引，应该怎么选择？



### 查询过程 普通索引 查到后 会继续 往下查找 直到不满足条件 唯一索引查到后直接返回

在查询过程中的影响是微乎其微的

假设，执行查询的语句是 select id from T where k=5。这个查询语句在索引树上查找的过程，先是通过 B+ 树从树根开始，按层搜索到叶子节点，也就是图中右下角的这个数据页，然后可以认为数据页内部通过二分法来定位记录。

对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。

对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。

那么，这个不同带来的性能差距会有多少呢？答案是，微乎其微。



### 更新过程

为了说明普通索引和唯一索引对更新语句性能的影响这个问题，我需要先跟你介绍一下 change buffer。

当需要更新一个数据页时，**如果数据页在内存中就直接更新**，而如果这个数据页还**没有在内存中**的话，在不影响数据一致性的前提下，InnoDB 会将这些**更新操作缓存在 change buffer 中**，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。



需要说明的是，虽然名字叫作 change buffer，**实际上它是可以持久化的数据**。也就是说，**change buffer 在内存中有拷贝，也会被写入到磁盘上**



将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。

#### 触发merge的时机

**除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge**。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。



显然，如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用 buffer pool 的，所以这种方式还能够避免占用内存，提高内存利用率。



#### 那么，什么条件下可以使用 change buffer 呢？

对于**唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。**比如，要插入 (4,400) 这个记录，就要先判断现在表中是否已经存在 k=4 的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。

**因此，唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。**



change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。



现在，你已经理解了 change buffer 的机制，那么我们再一起来看看**如果要在这张表中插入一个新记录 (4,400) 的话，InnoDB 的处理流程是怎样的。**

第一种情况是，**这个记录要更新的目标页在内存中**。这时，InnoDB 的处理流程如下：

- 对于唯一索引来说，找到 3 和 5 之间的位置，判断到没有冲突，插入这个值，语句执行结束；
- 对于普通索引来说，找到 3 和 5 之间的位置，插入这个值，语句执行结束。

这样看来，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的 CPU 时间。

但，这不是我们关注的重点。

第二种情况是，**这个记录要更新的目标页不在内存中**。这时，InnoDB 的处理流程如下：

- 对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；
- 对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。



将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。**change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。**



### change buffer 的使用场景

通过上面的分析，你已经清楚了使用 change buffer 对更新过程的加速作用，也清楚了 change buffer 只限于用在普通索引的场景下，而不适用于唯一索引。那么，现在有一个问题就是：**普通索引的所有场景，使用 change buffer 都可以起到加速作用吗？**



因为 merge 的时候是真正进行数据更新的时刻，而change buffer的主要目的就是将记录的变更动作缓存下来，**所以在一个数据页做 merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。**



因此，对于**写多读少**的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。



反过来，假设一个业务的更新模式是**写入之后马上会做查询**，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，**change buffer 反而起到了副作用**。



### 索引选择和实践

普通索引和唯一索引应该怎么选择。其实，**这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，我建议你尽量选择普通索引。**



如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。

在实际使用中，你会发现，普通索引和 change buffer 的配合使用，对于数据量大的表的更新优化还是很明显的。

特别地，在使用机械硬盘时，change buffer 这个机制的收效是非常显著的。所以，当你有一个类似“历史数据”的库，并且出于成本考虑用的是机械硬盘时，那你应该特别关注这些表里的索引，尽量使用普通索引，然后把 change buffer 尽量开大，以确保这个“历史数据”表的数据写入速度。



### change buffer 和 redo log

理解了 change buffer 的原理，你可能会联想到我在前面文章中和你介绍过的 redo log 和 WAL。

WAL 提升性能的核心机制，也的确是尽量减少随机读写，这两个概念确实容易混淆。

现在，我们要在表上执行这个插入语句：

```sql

mysql> insert into t(id,k) values(id1,k1),(id2,k2);
```



这里，我们假设当前 k 索引树的状态，查找到位置后，**k1 所在的数据页在内存 **(InnoDB buffer pool) 中，**k2 所在的数据页不在内存中。**如图 2 所示是带 change buffer 的更新状态图。

![img](https://static001.geekbang.org/resource/image/98/a3/980a2b786f0ea7adabef2e64fb4c4ca3.png)



​																	图 2 带 change buffer 的更新过程

分析这条更新语句，你会发现它涉及了四个部分：内存、redo log（ib_log_fileX）、 数据表空间（t.ibd）、系统表空间（ibdata1）。



这条更新语句做了如下的操作（按照图中的数字顺序）：

1. Page 1 在内存中，直接更新内存；
2. Page 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往 Page 2 插入一行”这个信息
3. 将上述两个动作记入 redo log 中（图中 3 和 4）。

做完上面这些，事务就可以完成了。所以，你会看到，执行这条更新语句的成本很低，就是写了两处内存，然后写了一处磁盘（两次操作合在一起写了一次磁盘(写磁盘表示)），而且还是顺序写的。



同时，图中的两个虚线箭头，是后台操作，不影响更新的响应时间。

那在这之后的读请求，要怎么处理呢？

比如，我们现在要执行 select * from t where k in (k1, k2)。这里，我画了这两个读请求的流程图。

如果读语句发生在更新语句后不久，内存中的数据都还在，那么此时的这两个读操作就与系统表空间（ibdata1）和 redo log（ib_log_fileX）无关了。所以，我在图中就没画出这两部分。

![img](https://static001.geekbang.org/resource/image/6d/8e/6dc743577af1dbcbb8550bddbfc5f98e.png)

​															图 3 带 change buffer 的读过程



从图中可以看到：

1.读 Page 1 的时候，直接从内存返回。有几位同学在前面文章的评论中问到，WAL 之后如果读数据，是不是一定要读盘，是不是一定要从 redo log 里面把数据更新以后才可以返回？其实是不用的。你可以看一下图 3 的这个状态，虽然磁盘上还是之前的数据，但是这里直接从内存返回结果，结果是正确的。

2.要读 Page 2 的时候，**需要把 Page 2 从磁盘读入内存中，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果**。



可以看到，直到需要读 Page 2 的时候，这个数据页才会被读入内存。

所以，如果要简单地对比这两个机制在提升更新性能上的收益的话，**redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。**



### 小结

由于唯一索引用不上 change buffer 的优化机制，因此如果业务可以接受，从性能角度出发我建议你优先考虑非唯一索引。





### 思考题

change buffer 一开始是写内存的，那么如果这个时候机器掉电重启，会不会导致 change buffer 丢失呢？change buffer 丢失可不是小事儿，再从磁盘读入数据可就没有了 merge 过程，就等于是数据丢失了。会不会出现这种情况呢？



# 16 | “order by”是怎么工作的？

一定会经常碰到需要根据指定的字段排序来显示结果的需求。还是以我们前面举例用过的市民表为例，假设你要查询城市是“杭州”的所有人名字，并且按照姓名排序返回前 1000 个人的姓名、年龄。

```sql

CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `city` varchar(16) NOT NULL,
  `name` varchar(16) NOT NULL,
  `age` int(11) NOT NULL,
  `addr` varchar(128) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `city` (`city`)
) ENGINE=InnoDB;
```

这时，你的 SQL 语句可以这么写

```sql
select city,name,age from t where city='杭州' order by name limit 1000  ;
```

order by name

### 全字段排序

前面我们介绍过索引，所以你现在就很清楚了，为避免全表扫描，我们需要在 city 字段加上索引。

在 city 字段上创建索引之后，我们用 explain 命令来看看这个语句的执行情况。

![img](https://static001.geekbang.org/resource/image/82/03/826579b63225def812330ef6c344a303.png)

​															图 1 使用 explain 命令查看语句的执行情况



Extra这个字段中的"Using filesort" 表示的是需要排序，**MySQL 会给每个线程分配一块内存用于排序，称为 sort_buffer**。

sort_buffer是在server层

为了说明这个 SQL 查询语句的执行过程，我们先来看一下 city 这个索引的示意图。

![img](https://static001.geekbang.org/resource/image/53/3e/5334cca9118be14bde95ec94b02f0a3e.png)



从图中可以看到，满足 city='杭州’条件的行，是从 ID_X 到 ID_(X+N) 的这些记录。通常情况下，这个语句执行流程如下所示 ：



通常情况下，这个语句执行流程如下所示 ：

1.初始化 sort_buffer，确定放入 name、city、age 这三个字段；

2.从索引 city 找到第一个满足 city='杭州’条件的主键 id，也就是图中的 ID_X；

3.到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中；

4.从索引 city 取下一个记录的主键 id；

5.重复步骤 3、4 直到 city 的值不满足查询条件为止，对应的主键 id 也就是图中的 ID_Y；

6.对 sort_buffer 中的数据按照字段 name 做**快速排序**；

7.按照排序结果取前 1000 行返回给客户端。



我们暂且把这个排序过程，称为全字段排序，执行流程的示意图如下所示，下一篇文章中我们还会用到这个排序。



![img](https://static001.geekbang.org/resource/image/6c/72/6c821828cddf46670f9d56e126e3e772.jpg)



图中“按 name 排序”这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数 sort_buffer_size。



sort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。





你可以用下面介绍的方法，来确定一个排序语句是否使用了临时文件

```sql

/* 打开optimizer_trace，只对本线程有效 */
SET optimizer_trace='enabled=on'; 

/* @a保存Innodb_rows_read的初始值 */
select VARIABLE_VALUE into @a from  performance_schema.session_status where variable_name = 'Innodb_rows_read';

/* 执行语句 */
select city, name,age from t where city='杭州' order by name limit 1000; 

/* 查看 OPTIMIZER_TRACE 输出 */
SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\G

/* @b保存Innodb_rows_read的当前值 */
select VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = 'Innodb_rows_read';

/* 计算Innodb_rows_read差值 */
select @b-@a;
```



这个方法是通过查看 OPTIMIZER_TRACE 的结果来确认的，你可以从 number_of_tmp_files 中看到是否使用了临时文件。

![img](https://static001.geekbang.org/resource/image/89/95/89baf99cdeefe90a22370e1d6f5e6495.png)

​										图 4 全排序的 OPTIMIZER_TRACE 部分结果



number_of_tmp_files 表示的是，排序过程中使用的临时文件数。你一定奇怪，为什么需要 12 个文件？内存放不下时，就需要使用外部排序，**外部排序一般使用归并排序算法**。可以这么简单理解，**MySQL 将需要排序的数据分成 12 份，每一份单独排序后存在这些临时文件中。然后把这 12 个有序文件再合并成一个有序的大文件**。





### rowid 排序

在上面这个算法过程里面，只对原表的数据读了一遍，剩下的操作都是在 sort_buffer 和临时文件中执行的。但这个算法有一个问题，**就是如果查询要返回的字段很多的话，那么 sort_buffer 里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差。**



那么，如果 MySQL 认为**排序的单行长度太大会怎么做呢？**

接下来，我来修改一个参数，让 MySQL 采用另外一种算法。

```sql
SET max_length_for_sort_data = 16;
```



max_length_for_sort_data，是 **MySQL 中专门控制用于排序的行数据的长度**的一个参数。它的意思是，如果**单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法**。



max_length_for_sort_data，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法。

新的算法放入 sort_buffer 的字段，**只有要排序的列（即 name 字段）和主键 id**。

但这时，排序的结果就因为少了 city 和 age 字段的值，不能直接返回了(**相当于避免了外部排序，但是多一次回表**)，整个执行流程就变成如下所示的样子：

1.初始化 sort_buffer，确定放入两个字段，即 name 和 id；

2.从索引 city 找到第一个满足 city='杭州’条件的主键 id，也就是图中的 ID_X；

3.到主键 id 索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中；

4.从索引 city 取下一个记录的主键 id；

5.重复步骤 3、4 直到不满足 city='杭州’条件为止，也就是图中的 ID_Y；

6.对 sort_buffer 中的数据按照字段 name 进行排序；

7.遍历排序结果，取前 1000 行，**并按照 id 的值回到原表中取出 city、name 和 age 三个字段返回给客户端**。



这个执行流程的示意图如下，我把它称为 rowid 排序。

![img](https://static001.geekbang.org/resource/image/dc/6d/dc92b67721171206a302eb679c83e86d.jpg)

对比图 3 的全字段排序流程图你会发现，**rowid 排序多访问了一次表 t 的主键索引**，就是步骤 7。



需要说明的是，最后的“结果集”是一个逻辑概念，实际上 MySQL 服务端从排序后的 sort_buffer 中依次取出 id，然后到原表查到 city、name 和 age 这三个字段的结果，不需要在服务端再耗费内存存储结果，是直接返回给客户端的。



### 全字段排序 VS rowid 排序

如果 MySQL 实在是担心排序内存太小，会影响排序效率，才会采用 rowid 排序算法，这样排序过程中一次可以排序更多行，但是需要再回到原表去取数据。

如果 MySQL 认为内存足够大，会优先选择全字段排序，把需要的字段都放到 sort_buffer 中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据。



这也就体现了 MySQL 的一个设计思想：**如果内存够，就要多利用内存，尽量减少磁盘访问。**

对于 InnoDB 表来说，rowid 排序会要求回表多造成磁盘读，因此不会被优先选择。



### 如何避免去排序操作呢？把order by的字段和前面的where字段 建立联合索引

直接建立联合索引，我们可以在这个市民表上创建一个 city 和 name 的联合索引，对应的 SQL 语句是：

```sql
alter table t add index city_user(city, name);
```

作为与 city 索引的对比，我们来看看这个索引的示意图。

![img](https://static001.geekbang.org/resource/image/f9/bf/f980201372b676893647fb17fac4e2bf.png)

在这个索引里面，我们依然可以用树搜索的方式定位到第一个满足 city='杭州’的记录，并且额外确保了，接下来按顺序取“下一条记录”的遍历过程中，只要 city 的值是杭州，name 的值就一定是有序的。

这样整个查询过程的流程就变成了：



1.从索引 (city,name) 找到第一个满足 city='杭州’条件的主键 id；

2.到主键 id 索引取出整行，取 name、city、age 三个字段的值，作为结果集的一部分直接返回；

3.从索引 (city,name) 取下一个记录主键 id；

4.重复步骤 2、3，直到查到第 1000 条记录，或者是不满足 city='杭州’条件时循环结束。

![img](https://static001.geekbang.org/resource/image/3f/92/3f590c3a14f9236f2d8e1e2cb9686692.jpg)



可以看到，这个查询过程不需要临时表，也不需要排序。接下来，我们用 explain 的结果来印证一下。

![img](https://static001.geekbang.org/resource/image/fc/8a/fc53de303811ba3c46d344595743358a.png)

图 9 引入 (city,name) 联合索引后，查询语句的执行计划

从图中可以看到，Extra 字段中没有 Using filesort 了，也就是不需要排序了。变为了Using index condition 而且由于 (city,name) 这个联合索引本身有序，所以这个查询也不用把 4000 行全都读一遍，只要找到满足条件的前 1000 条记录就可以退出了。也就是说，在我们这个例子里，只需要扫描 1000 次。

type=ref表示 上述表的**连接匹配条件，即哪些列或常量被用于查找索引列上的值**

既然说到这里了，我们再往前讨论，这个语句的执行流程有没有可能进一步简化呢？不知道你还记不记得，我在第 5 篇文章《 深入浅出索引（下）》中，和你介绍的覆盖索引。



这里我们可以再稍微复习一下。覆盖索引是指，索引上的信息足够满足查询请求，不需要再回到主键索引上去取数据。按照覆盖索引的概念，我们可以再优化一下这个查询语句的执行流程。针对这个查询，我们可以创建一个 city、name 和 age 的联合索引，对应的 SQL 语句就是：

```sql
alter table t add index city_user_age(city, name, age);
```

这时，对于 city 字段的值相同的行来说，还是按照 name 字段的值递增排序的，此时的查询语句也就不再需要排序了。这样整个查询语句的执行流程就变成了：

1.从索引 (city,name,age) 找到第一个满足 city='杭州’条件的记录，取出其中的 city、name 和 age 这三个字段的值，作为结果集的一部分直接返回；

2.从索引 (city,name,age) 取下一个记录，同样取出这三个字段的值，作为结果集的一部分直接返回；重复执行步骤 2，

3.直到查到第 1000 条记录，或者是不满足 city='杭州’条件时循环结束。

![img](https://static001.geekbang.org/resource/image/df/d6/df4b8e445a59c53df1f2e0f115f02cd6.jpg)

​														图 10 引入 (city,name,age) 联合索引后，查询语句的执行流程



然后，我们再来看看 explain 的结果。

![img](https://static001.geekbang.org/resource/image/9e/23/9e40b7b8f0e3f81126a9171cc22e3423.png)

图 11 引入 (city,name,age) 联合索引后，查询语句的执行计划

可以看到，Extra 字段里面多了“Using index”，表示的就是使用了覆盖索引，性能上会快很多。当然，这里并不是说要为了每个查询能用上覆盖索引，就要把语句中涉及的字段都建上联合索引，毕竟索引还是有维护代价的。这是一个需要权衡的决定。



小结



# 11 | 怎么给字符串字段加索引？







### 前缀索引

```sql
mysql> alter table SUser add index index1(email);
或
mysql> alter table SUser add index index2(email(6));
```

第二句sql 就是前缀索引的添加方法



使用前缀索引的好处：可以节省索引的空间 如果前缀的长度选取合适。就可以做到既节省空间，又不用额外增加太多的查询成本。



坏处：还是有可能增加匹配长度，同时会是**覆盖索引**失效，因此如果有查询语句要用到覆盖索引的时候，就要避免使用前缀索引。

### 其他方式

对于类似于邮箱这样的字段来说，使用前缀索引的效果可能还不错。但是，遇到前缀的区分度不够好的情况时，我们要怎么办呢？



比如，我们国家的身份证号，一共18位，其中前6位是地址码，所以同一个县的人的身份证号前 6 位一般会是相同的。

假设你维护的数据库是一个市的公民信息系统，这时候如果对身份证号做长度为 6 的前缀索引的话，这个索引的区分度就非常低了。按照我们前面说的方法，可能你需要创建长度为 12 以上的前缀索引，才能够满足区分度要求。



那么，如果我们能够确定业务需求里面只有按照身份证进行等值查询的需求，还有没有别的处理方法呢？这种方法，既可以占用更小的空间，也能达到相同的查询效率。

**第一种方式是使用倒序存储**。如果你存储身份证号的时候把它倒过来存，每次查询的时候，你可以这么写：

```sql
mysql> select field_list from t where id_card = reverse('input_id_card_string');
```

由于身份证号的最后 6 位没有地址码这样的重复逻辑，所以最后这 6 位很可能就提供了足够的区分度。当然了，实践中你不要忘记使用 count(distinct) 方法去做个验证。



**第二种方式是使用 hash 字段**。你可以在表上**再创建一个整数字段，来保存身份证的校验码，同时在这个字段上创建索引**。

```sql

mysql> alter table t add id_card_crc int unsigned, add index(id_card_crc);
```



然后每次插入新记录的时候，都同时用 crc32() 这个函数得到校验码填到这个新字段。由于校验码可能存在冲突，也就是说两个不同的身份证号通过 crc32() 函数得到的结果可能是相同的，所以你的查询语句 where 部分要判断 id_card 的值是否精确相同。

```sql

mysql> select field_list from t where id_card_crc=crc32('input_id_card_string') and id_card='input_id_card_string'
```



这样，索引的长度变成了 4 个字节，比原来小了很多。



接下来，我们再一起看看使用**倒序存储和使用 hash 字段这两种方法的异同点**。



首先，它们的相同点是，**都不支持范围查询**。倒序存储的字段上创建的索引是按照倒序字符串的方式排序的，已经没有办法利用索引方式查出身份证号码在[ID_X, ID_Y]的所有市民了。同样地，hash 字段的方式也只能支持等值查询。



它们的区别，主要体现在以下三个方面：

1.从**占用的额外空间**来看，倒叙存储方式在主键索引上，不会消耗额外的存储空间，而hash字段方法需要增加几个字段。当然，倒序存储方式使用 4 个字节的前缀长度应该是不够的，如果再长一点，这个消耗跟额外这个 hash 字段也差不多抵消了。

2.在 **CPU 消耗**方面，倒序方式每次写和读的时候，都需要额外调用一次 reverse 函数，而 hash 字段的方式需要额外调用一次 crc32() 函数。如果只从这两个函数的计算复杂度来看的话，**reverse 函数额外消耗的 CPU 资源会更小些**。

3.从查询效率上看，使用 hash 字段方式的查询性能相对更稳定一些。因为 crc32 算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近 1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。



### 小结



1. 直接创建完整索引，这样可能比较占用空间；
2. 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；
3. 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；
4. 创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。





# 13 | 为什么表数据删掉一半，表文件大小不变？



### 参数 innodb_file_per_table

表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数 innodb_file_per_table 控制的：

1. 这个参数设置为 OFF 表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起；
2. 这个参数设置为 **ON** 表示的是，每个 InnoDB 表数据存储在一个以 **.ibd 为后缀**的文件中。

从 MySQL 5.6.6 版本开始，它的默认值就是 ON 了。

我建议你不论使用 MySQL 的哪个版本，都将这个值设置为 ON。因为，一个表单独存储为一个文件更容易管理，而且在你不需要这个表的时候，通过 drop table 命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。



所以，**将 innodb_file_per_table 设置为 ON**，是推荐做法，我们接下来的讨论都是基于这个设置展开的。

我们在删除整个表的时候，可以使用 drop table 命令回收表空间。但是，我们遇到的更多的删除数据的场景是删除某些行，这时就遇到了我们文章开头的问题：表中的数据被删除了，但是表空间却没有被回收。

### 数据删除流程

InnoDB 里的数据都是用 B+ 树的结构组织的。

![img](https://static001.geekbang.org/resource/image/f0/c8/f0b1e4ac610bcb5c5922d0b18563f3c8.png)

​																图 1 B+ 树索引示意图

假设，我们**要删掉 R4 这个记录，InnoDB 引擎只会把 R4 这个记录标记为删除**。如果之后要再插入一个 ID 在 300 和 600 之间的记录时，可能会复用这个位置。但是，磁盘文件的大小并不会缩小。

#### 现在，你已经知道了 InnoDB 的数据是按页存储的，那么如果我们删掉了一个数据页上的所有记录，会怎么样？

答案是，整个数据页就可以被复用了。

但是，**数据页的复用跟记录的复用是不同的**。

记录的复用，只限于符合范围条件的数据。比如上面的这个例子，R4 这条记录被删除后，如果插入一个 ID 是 400 的行，可以直接复用这个空间。但如果插入的是一个 ID 是 800 的行，就不能复用这个位置了。

而当整个页从 B+ 树里面摘掉以后，可以复用到任何位置。以图 1 为例，如果将数据页 page A 上的所有记录删除以后，page A 会被标记为可复用。这时候如果要插入一条 ID=50 的记录需要使用新页的时候，page A 是可以被复用的。



如果相邻的两个数据页利用率都很小，**系统就会把这两个页上的数据合到其中一个页上，另外一个数据页就被标记为可复用**。



进一步地，如果我们用 delete 命令把整个表的数据删除呢？结果就是，**所有的数据页都会被标记为可复用。但是磁盘上，文件不会变小**

你现在知道了，**delete 命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的**。也就是说，通过 delete 命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是“空洞”。

实际上，**不止是删除数据会造成空洞，插入数据也会。**



如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果数据是随机插入的，就可能造成索引的数据页分裂。

假设图 1 中 page A 已经满了，这时我要再插入一行数据，会怎样呢？

![img](https://static001.geekbang.org/resource/image/80/ea/8083f05a4a4c0372833a6e01d5a8e6ea.png)

​													图 2 插入数据导致页分裂

可以看到，由于 page A 满了，再插入一个 ID 是 550 的数据时，就不得不再申请一个新的页面 page B 来保存数据了。页分裂完成后，page A 的末尾就留下了空洞（注意：实际上，可能不止 1 个记录的位置是空洞）。

另外，更新索引上的值，可以理解为删除一个旧的值，再插入一个新值。不难理解，这也是会造成空洞的。

也就是说，经过大量增删改的表，都是可能是存在空洞的。所以，如果能够把这些空洞去掉，就能达到收缩表空间的目的。

而重建表，就可以达到这样的目的。



### 重建表

试想一下，如果你现在有一个表 A，需要做空间收缩，为了把表中存在的空洞去掉，你可以怎么做呢？

你可以新建一个与表 A 结构相同的表 B，然后按照主键 ID 递增的顺序，把数据一行一行地从表 A 里读出来再插入到表 B 中。

由于表 B 是新建的表，所以表 A 主键索引上的空洞，在表 B 中就都不存在了。显然地，表 B 的主键索引更紧凑，数据页的利用率也更高。如果我们把表 B 作为临时表，数据从表 A 导入表 B 的操作完成后，用表 B 替换 A，从效果上看，就起到了收缩表 A 空间的作用。

这里，你可以使用 alter table A engine=InnoDB 命令来重建表。在 MySQL 5.5 版本之前，这个命令的执行流程跟我们前面描述的差不多，区别只是这个临时表 B 不需要你自己创建，MySQL 会自动完成转存数据、交换表名、删除旧表的操作。

![img](https://static001.geekbang.org/resource/image/02/cd/02e083adaec6e1191f54992f7bc13dcd.png)

​															图 3 改锁表 DDL

显然，花时间最多的步骤是往临时表插入数据的过程，如果在这个过程中，有新的数据要写入到表 A 的话，就会造成数据丢失。因此，在整个 DDL 过程中，表 A 中不能有更新。也就是说，这个 DDL 不是 Online 的。

而在 MySQL 5.6 版本开始引入的 Online DDL，对这个操作流程做了优化。

我给你简单描述一下引入了 Online DDL 之后，重建表的流程：

1. 建立一个临时文件，扫描表 A 主键的所有数据页；
2. 用数据页中表 A 的记录生成 B+ 树，存储到临时文件中；
3. 生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，对应的是图中 state2 的状态；
4. 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，对应的就是图中 state3 的状态；
5. 用临时文件替换表 A 的数据文件。

![img](https://static001.geekbang.org/resource/image/2d/f0/2d1cfbbeb013b851a56390d38b5321f0.png)

​																			图 4 Online DDL





# 20 | 幻读是什么，幻读有什么问题？



建表和初始化语句

```sql
CREATE TABLE `t` ( 
    `id` int(11) NOT NULL, 
    `c` int(11) DEFAULT NULL, 
    `d` int(11) DEFAULT NULL, 
    PRIMARY KEY (`id`), 
    KEY `c` (`c`)
) ENGINE=InnoDB;
insert into t values(0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,20),(25,25,25);
```

这个**表除了一个主键id外，还有一个索引c**，初始化语句在表中插入了 6 行数据。





上期我留给你的问题是，下面的语句序列，是怎么加锁的，加的锁又是什么时候释放的呢？

```sql
begin;
select * from t where d=5 for update;
commit;
```

比较好理解的是，这个语句会命中d=5这一行，对应的主键id=5，因此在 select 语句执行完成后，id=5 这一行会加一个写锁，而且由于两阶段锁协议，这个写锁会在执行 commit 语句的时候释放。



由于字段d上没有索引，因此这条查询语句会做全表扫描。那么，其他被扫描到的，但是不满足条件的5行记录上，会不会被加锁呢。

对于问题的回答: 

1. 全表扫描一般指 主键索引树扫描; 

2.  对于会不会被加锁: 

   2.1 : RC级别下,只会在满足条件的行加行锁(直到事务commit/rollback才会释放),不满足的直接释放; 

   2.2: RR级别下会加行锁 + Gap lock,会将(0,5],(5,10],(10,15]这三个区间间隙锁起来（next-key lock是左开右闭, Gap-Lock是左开右开）;



由于字段 d 上没有索引，因此这条查询语句会做全表扫描。那么，其他被扫描到的，但是不满足条件的 5 行记录上，会不会被加锁呢？

我们知道，InnoDB 的默认事务隔离级别是可重复读，所以本文接下来没有特殊说明的部分，都是设定在可重复读隔离级别下。



## 幻读是什么？

现在，我们就来分析一下，如果只在 id=5 这一行加锁，而其他行的不加锁的话，会怎么样。

下面先来看一下这个场景（注意：这是我假设的一个场景）：

![img](https://static001.geekbang.org/resource/image/5b/8b/5bc506e5884d21844126d26bbe6fa68b.png)



​								图 1 假设只在 id=5 这一行加行锁



可以看到，session A 里执行了三次查询，分别是 Q1、Q2 和 Q3。它们的 SQL 语句相同，都是 select * from t where d=5 for update。这个语句的意思你应该很清楚了，查所有 d=5 的行，而且使用的是当前读，并且加上写锁。现在，我们来看一下这三条 SQL 语句，分别会返回什么结果。

1. Q1 只返回 id=5 这一行；
2. 在 T2 时刻，session B 把 id=0 这一行的 d 值改成了 5，因此 T3 时刻 Q2 查出来的是 id=0 和 id=5 这两行；
3. 在 T4 时刻，session C 又插入一行（1,1,5），因此 T5 时刻 Q3 查出来的是 id=0、id=1 和 id=5 的这三行。

其中，Q3 读到 id=1 这一行的现象，被称为“幻读”。也就是说，幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。



这里，我需要对“幻读”做一个说明：

1. 在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现。(不准确 快照读也会有幻读)
2. 上面 session B 的修改结果，被 session A 之后的 select 语句用“当前读”看到，不能称为幻读。幻读仅专指“新插入的行”。



因为这三个查询都是加了 for update，都是当前读。而当前读的规则，就是要能读到所有已经提交的记录的最新值。并且，session B 和 sessionC 的两条语句，执行后就会提交，所以 Q2 和 Q3 就是应该看到这两个事务的操作效果，而且也看到了，这跟事务的可见性规则并不矛盾。

但是，这是不是真的没问题呢？

不，这里还真就有问题。

## 幻读有什么问题？

首先是语义上的。session A 在 T1 时刻就声明了，**“我要把所有 d=5 的行锁住，不准备的事务进行读写操作”。而实际上，这个语义被破坏了。**

如果现在这样看感觉还不明显的话，我再往 session B 和 session C 里面分别加一条 SQL 语句，你再看看会出现什么现象。

![img](https://static001.geekbang.org/resource/image/7a/07/7a9ffa90ac3cc78db6a51ff9b9075607.png)

​														图 2 假设只在 id=5 这一行加行锁 -- 语义被破坏

session B 的第二条语句 update t set c=5 where id=0，语义是“我把 id=0、d=5 这一行的 c 值，改成了 5”。

由于在 T1 时刻，session A 还只是给 id=5 这一行加了行锁， 并没有给 id=0 这行加上锁。因此，session B 在 T2 时刻，是可以执行这两条 update 语句的。这样，就破坏了 session A 里 Q1 语句要锁住所有 d=5 的行的加锁声明。





#### 这个数据不一致到底是怎么引入的？

我们分析一下可以知道，这是我们假设“select * from t where d=5 for update 这条语句只给 d=5 这一行，也就是 id=5 的这一行加锁”导致的。所以我们认为，上面的设定不合理，要改。





那怎么改呢？我们把扫描过程中碰到的行，也都加上写锁，再来看看执行效果。

![img](https://static001.geekbang.org/resource/image/34/47/34ad6478281709da833856084a1e3447.png)

​		图 4 假设扫描到的行都被加上了行锁

由于 session A 把所有的行都加了写锁，所以 session B 在执行第一个 update 语句的时候就被锁住了。需要等到 T6 时刻 session A 提交以后，session B 才能继续执行。



## 如何解决幻读？

现在你知道了，产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)。

顾名思义，间隙锁，锁的就是两个值之间的空隙。比如文章开头的表 t，初始化插入了 6 个记录，这就产生了 7 个间隙。

![img](https://static001.geekbang.org/resource/image/e7/61/e7f7ca0d3dab2f48c588d714ee3ac861.png)

​						图 5 表 t 主键索引上的行锁和间隙锁

这样，当你执行 select * from t where d=5 for update 的时候，**就不止是给数据库中已有的 6 个记录加上了行锁，还同时加了 7 个间隙锁。这样就确保了无法再插入新的记录。**

也就是说这时候，在一行行扫描的过程中，不仅将给行加上了行锁，还给行两边的空隙，也加上了间隙锁。

现在你知道了，**数据行是可以加上锁的实体，数据行之间的间隙，也是可以加上锁的实体。但是间隙锁跟我们之前碰到过的锁都不太一样。**

比如行锁，分成读锁和写锁。下图就是这两种类型行锁的冲突关系。

![img](https://static001.geekbang.org/resource/image/c4/51/c435c765556c0f3735a6eda0779ff151.png)



​																						图 6 两种行锁间的冲突关系



也就是说，跟行锁有冲突关系的是“另外一个行锁”。

但是间隙锁不一样，**跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作。间隙锁之间都不存在冲突关系**。

这句话不太好理解，我给你举个例子：

![img](https://static001.geekbang.org/resource/image/7c/98/7c37732d936650f1cda7dbf27daf7498.png)

图 7 间隙锁之间不互锁

这里 session B 并不会被堵住。因为表 t 里并没有 c=7 这个记录，因此 session A 加的是间隙锁 (5,10)。而 session B 也是在这个间隙加的间隙锁。**它们有共同的目标，即：保护这个间隙，不允许插入值。但，它们之间是不冲突的。**



**间隙锁和行锁合称 next-key lock**，**每个 next-key lock 是前开后闭区间**。也就是说，我们的表 t 初始化以后，如果用 select * from t for update 要把整个表所有记录锁起来，就形成了 7 个 next-key lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +supremum]。

> 备注：这篇文章中，如果没有特别说明，我们把间隙锁记为开区间，把 next-key lock 记为前开后闭区间。

你可能会问说，这个 supremum 从哪儿来的呢？这是因为 +∞是开区间。实现上，InnoDB 给每个索引加了一个不存在的最大值 supremum，这样才符合我们前面说的“都是前开后闭区间”

**间隙锁和 next-key lock 的引入，帮我们解决了幻读的问题，但同时也带来了一些“困扰”。**



![img](https://static001.geekbang.org/resource/image/df/be/df37bf0bb9f85ea59f0540e24eb6bcbe.png)

你看到了，其实都不需要用到后面的 update 语句，就已经形成死锁了。我们按语句执行顺序来分析一下：



1.sessionA 执行 select … for update 语句，由于 id=9 这一行并不存在，因此会加上间隙锁 (5,10);

2.session B 执行 select … for update 语句，同样会加上间隙锁 (5,10)，间隙锁之间不会冲突，因此这个语句可以执行成功；

3.session B 试图插入一行 (9,9,9)，被 session A 的间隙锁挡住了，只好进入等待；

4.session A 试图插入一行 (9,9,9)，被 session B 的间隙锁挡住了。

至此，两个 session 进入互相等待状态，形成死锁。当然，InnoDB 的死锁检测马上就发现了这对死锁关系，让 session A 的 insert 语句报错返回了。









### 总结：

1. 间隙锁或者next-key lock才能解决幻读 
2. 间隙锁之间是互不冲突的，因为他们的共同目标是，保护这个间隙不允许插入值

3. next-key lock是时在RR级别下才有的。
4. 间隙锁的问题，会影响并发度，容易造成dead-lock





# 21 | 为什么我只改一行的语句，锁这么多？mysql加锁规则



这个规则有以下两条前提说明：

1. MySQL 后面的版本可能会改变加锁策略，所以这个规则只限于截止到现在的最新版本，即 5.x 系列 <=5.7.24，8.0 系列 <=8.0.13。

2. 如果大家在验证中有发现 bad case 的话，请提出来，我会再补充进这篇文章，使得一起学习本专栏的所有同学都能受益。

**因为间隙锁在可重复读隔离级别下才有效**，所以本篇文章接下来的描述，若没有特殊说明，默认是**可重复读隔离级别**。



**我总结的加锁规则里面，包含了两个“原则”、两个“优化”和一个“bug”。**



1. 原则1：加锁的基本单位是next-key lock 希望你还记得，next-key lock 是前开后闭区间。
2. 原则2：查找过程中访问到的对象才会加锁
3. 优化 1：索引上的**等值查询**，给**唯一索引加锁的时候，next-key lock 退化为行锁**。
4. 优化 2：索引上的**等值查询**，**向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁**。

5. 一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。



我还是以上篇文章的表 t 为例，和你解释一下这些规则。表 t 的建表语句和初始化语句如下。

```sql
CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `c` int(11) DEFAULT NULL,
  `d` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `c` (`c`)
) ENGINE=InnoDB;

insert into t values(0,0,0),(5,5,5),
(10,10,10),(15,15,15),(20,20,20),(25,25,25);
```









# 22 | MySQL有哪些“饮鸩止渴”提高性能的方法？

## 短连接风暴







# 25 | MySQL是怎么保证高可用的？



在一个主备关系中，每个备库接收主库的 binlog 并执行。

正常情况下，只要主库执行更新生成的所有 binlog，都可以传到备库并被正确地执行，备库就能达到跟主库一致的状态，这就是最终一致性。但是，MySQL 要提供高可用能力，只有**最终一致性**是不够的。为什么这么说呢？今天我就着重和你分析一下。

这里，我再放一次上一篇文章中讲到的双 M 结构的主备切换流程图。

![img](https://static001.geekbang.org/resource/image/89/cc/89290bbcf454ff9a3dc5de42a85a69cc.png)




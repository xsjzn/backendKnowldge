# 操作系统基础

冯诺依曼模型
在 1945 年冯诺依曼和其他计算机科学家们提出了计算机具体实现的报告，其遵循了图灵机的
设计，⽽且还提出⽤电⼦元件构造计算机，并约定了⽤⼆进制进⾏计算和存储，还定义计算
机基本结构为 5 个部分，分别是**中央处理器（CPU）、内存、输⼊设备、输出设备、总线**。
这 5 个部分也被称为冯诺依曼模型，接下来看看这 5 个部分的具体作⽤。

## 1.什么是操作系统？

1. **操作系统（Operating System，简称 OS）是管理计算机硬件与软件资源的程序，是计算机的基石。**
2. **操作系统本质上是一个运行在计算机上的软件程序 ，用于管理计算机硬件和软件资源。** 举例：运行在你电脑上的所有应用程序都通过操作系统来调用系统内存以及磁盘等等硬件。
3. **操作系统存在屏蔽了硬件层的复杂性。** 操作系统就像是硬件使用的负责人，统筹着各种相关事项。
4. **操作系统的内核（Kernel）是操作系统的核心部分，它负责系统的内存管理，硬件设备的管理，文件系统的管理以及应用程序的管理**。 内核是连接应用程序和硬件的桥梁，决定着系统的性能和稳定性。

## 2.**什么是系统调用呢？** 能不能详细介绍一下。

进程在系统上的运行分为两个级别：

1. 用户态： 用户态运行的进程可**以直接读取用户程序的数据**
2. 内核态：可以简单的理解系统态运行的进程或**程序几乎可以访问计算机的任何资源，不受限制**。

我们运行的**程序基本都是运行在用户态**，如果我们调用**操作系统提供的系统态级别的子功能咋办呢？**那就需要**系统调用**了！

我们运行的用户程序中，凡是与系统态级别的资源有关的操作（如文件管理、进程控制、内存管理等)，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。

系统调用功能大致可以分为以下几类：

- **设备**管理。完成设备的请求或释放，以及设备启动等功能。
- **文件**管理。完成文件的读、写、创建及删除等功能。
- **进程控制**。完成进程的创建、撤销、阻塞及唤醒等功能。
- **进程通信**。完成进程之间的消息传递或信号传递等功能。
- **内存**管理。完成内存的分配、回收以及获取作业占用内存区大小及地址等功能。

## 一、进程管理

## 3.进程有哪几种状态?

5种：

**创建**状态

**就绪**状态

**运行**状态

**阻塞**状态

**结束**状态

### 3.1进程和线程

- **进程**是具有一定独立功能的程序关于某个数据集合上的一次运行活动，**进程是系统进行资源分配和调度的一个独立单位**
- **线程**是进程的一个实体，**是CPU调度和分派的基本单位**，它是比进程更小的**能独立运行的基本单位**

进程和线程的关系与区别：

1. 层级和数量关系：

   一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。线程是OS调度的最小单位

2. 资源分配

   资源分配给进程，多个线程共享进程的**堆**和**方法区 (JDK1.8 之后的元空间)资源，但是每个线程有自己的\**程序计数器**、**虚拟机栈** 和 **本地方法栈**。

3. CPU分配

   **处理机分给线程，即真正在处理机上运行的是线程**

   进程是**资源分配的最小单位**，线程是**CPU调度的最小单位**

4. 同步与通信方式：

   线程在执行过程中需要同步，不同进程的线程间要利用**消息通信**的办法实现同步

   进程可以通过 管道 有名管道 消息队列 共享内存 信号量 信号等方式同喜

   而线程则依靠信号量 互斥量以及等待通知

5. 切换开销：

   进程上下文切换开销大，线程开销小



### **3.2.为什么进程上下文切换比线程上下文切换代价高？ **进程切花 需要切换页目录

进程切换分两步：

1. **切换页目录**以及**新的地址空间**
2. 切换**内核栈以及硬件上下文**

对于linux来说，线程和进程的最大区别就在于**地址空间**，对于线程切换，第一步是不需要的，也就是说**不需要切换页目录以及新的地址空**

切换的性能消耗：

- 内核的这种切换过程伴随的最显著的性能损耗是将**寄存器中的内容切换出**
- 另外一个隐藏的损耗是上下文的切换会扰乱处理器的**缓存机制**，一旦去切换上下文，处理器中所有已经缓存的内存地址一瞬间都作废了。还有一个显著的区别是当你改变虚拟内存空间的时候，处理的**页表缓冲（processor's Translation Lookaside Buffer (TLB)）**或者相当的神马东西会**被全部刷新**，这将导致内存的访问在一段时间内相当的低效。但是在线程的切换中，不会出现这个问题

#### 进程的控制结构

在操作系统中，是用**进程控制块**（*process control block，PCB*）数据结构来描述进程的。

> 每个 PCB 是如何组织的呢？

通常是通过**链表**的方式进行组织，把具有**相同状态的进程链在一起，组成各种队列**。比如：

- 将所有处于就绪状态的进程链在一起，称为**就绪队列**；
- 把所有因等待某事件而处于等待状态的进程链在一起就组成各种**阻塞队列**；
- 另外，对于运行队列在**单核 CPU 系统中则只有一个运行指针**了，因为单核 CPU 在某个时间，只能运行一个程序。

那么，就绪队列和阻塞队列链表的组织形式如下图：

![图片](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcvw4t9kicec370n3cvX2JS9q2vgjxfNQq38MNmricWU9jicJtxKDqu8MiaFtvia2qJ7LVxjlsMCcRDShQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)





除了链接的组织方式，还有**索引方式**，它的工作原理：**将同一状态的进程组织在一个索引表中，索引表项指向相应的 PCB，不同状态对应不同的索引表**。

一般会选择链表，因为可能面临进程创建，销毁等调度导致进程状态发生变化，所以链表能够更加灵活的插入和删除。



那么，操作系统是如何创建进程的呢？**对于操作系统，进程就是一个数据结构**，我们直接来看 Linux 的源码：

```c
struct task_struct{
    //进程状态
    long state;
    //虚拟内存结构体
    struct mm_struct *mm;
    //进程号 
    pid_t pid;
    //指向父进程的指针
    struct task_struc __rcu *parent;
    //子进程列表
    struct list_head children;
    //存放文件系统信息的指针
    struct fs_struct        *fs;
    // 一个数组，包含该进程打开的文件指针
    struct files_struct        *files;
}
```

`task_struct`是 Linux内核对于一个进程的描述，也可以称为**进程描述符**。源码比较复杂，我这里就截取了一小部分比较常见的。

















## 4.进程通信有哪几种方式及其优缺点？

![image-20210413155724677](E:\typora-user-images\image-20210413155724677.png)

每个进程的用户地址空间都是独立的，一般而言是不能互相访问的，但内核空间是每个进程都共享的，所以**进程之间要通信必须通过内核**。

![image-20210413155751706](E:\typora-user-images\image-20210413155751706.png)

Linux 内核提供了不少进程间通信的机制



### 1.**管道/匿名管道(Pipes)**:

如果你学过 Linux 命令，那你肯定很熟悉「`|`」这个竖线。

`$ ps auxf | grep mysql`

上面命令行里的「`|`」竖线就是一个**管道**，它的功能是将前一个命令（`ps auxf`）的输出，作为后一个命令（`grep mysql`）的输入，从这功能描述，可以看出**管道传输数据是单向的**，如果想相互通信，我们需要创建两个管道才行。

同时，我们得知上面这种管道是没有名字，所以「`|`」表示的管道称为**匿名管道**，用完了就销毁。





用于具有**亲缘关系的父子进程间或者兄弟进程**之间的通信,管道是**单向的、先进先出的、无结构的、固定大小的字节流**，它把一个进程的标准输出和另一个进程的标准输入连接在一起。写进程在管道的尾端写入数据，读进程在管道的首端读出数据。数据读出后将从管道中移走，其它读进程都不能再读到这些数据。管道提供了简单的流控制机制。进程试图读空管道时，在有数据写入管道前，进程将一直阻塞。同样地，管道已经满时，进程再试图写管道，在其它进程从管道中移走数据之前，写进程将一直阻塞。

优点：简单方便；

缺点：1）局限于**单向通信** 2）只能创建在它的进程以及其有**亲缘关系的进程之间**;3）**缓冲区有限**；



### 2.**有名管道(Names Pipes)** : 

管道还有另外一个类型是**命名管道**，也被叫做 `FIFO`，因为数据是先进先出的传输方式。

在使用命名管道前，先需要通过 `mkfifo` 命令来创建，并且指定管道名字：

```
$ mkfifo myPipe
```

myPipe 就是这个管道的名称，基于 Linux 一切皆文件的理念，所以管道也是以文件的方式存在，我们可以用 ls 看一下，这个文件的类型是 p，也就是 pipe（管道） 的意思：

$ ls -l
prw-r--r--. 1 root  root     0 Jul 17 02:45 myPipe

接下来，我们往 myPipe 这个管道写入数据：

```
$ echo "hello" > myPipe  // 将数据写进管道
                         // 停住了 ...
```

> echo命令的功能是在显示器上显示一段文字，一般起到一个提示的作用。

你操作了后，你会发现命令执行后就停在这了，这是因为管道里的内容没有被读取，只有当管道里的数据被读完后，命令才可以正常退出。

于是，我们执行另外一个命令来读取这个管道里的数据：

```
$ cat < myPipe  // 读取管道里的数据
hello
```

> cat（英文全拼：concatenate）命令用于连接文件并打印到标准输出设备上。

匿名管道由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道，有名管道严格遵循**先进先出(first in first out)**。有名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。

可以看到，管道里的内容被读取出来了，并打印在了终端上，另外一方面，echo 那个命令也正常退出了。

我们可以看出，**管道这种通信方式效率低，不适合进程间频繁地交换数据**。当然，它的好处，自然就是简单，同时也我们很容易得知管道里的数据已经被另一个进程读取了。

优点：可以实现**任意关系的进程间的通信**；

缺点：1）**长期存于系统中，使用不当容易出错**；2）**缓冲区有限** 3)通信效率低，不适合频繁的交换数据



#### 那管道如何创建呢，背后原理是什么？

匿名管道的创建，需要通过下面这个**系统调用**

```
int pipe(int fd[2])
```

这里表示创建一个匿名管道，并**返回了两个描述符**，一个是管道的**读取端描述符`fd[0]`**，另一个是管道的**写入端描述符 `fd[1]`**。注意，这个**匿名管道是特殊的文件，只存在于内存，不存于文件系统中**。

![image-20210413160536413](E:\typora-user-images\image-20210413160536413.png)

其实，**所谓的管道，就是内存里面的一串缓存**。从管道的一段写入的数据，实际上是**缓存在内核中**的，另一端读取，也就是从内核中读取这段数据。另外，管道传输的**数据是无格式的流且大小受限**。

看到这，你可能会有疑问了，这两个描述符都是在一个进程里面，并没有起到进程间通信的作用，怎么样才能使得管道是跨过两个进程的呢？

我们可以使用 `fork` **创建子进程**，**创建的子进程会复制父进程的文件描述符**，这样就做到了两个进程各有两个「 `fd[0]` 与 `fd[1]`」，两个进程就可以通过各自的 fd 写入和读取同一个管道文件实现跨进程通信了。

![image-20210413160718084](E:\typora-user-images\image-20210413160718084.png)

管道只能一端写入，另一端读出，所以上面这种模式容易造成混乱，因为父进程和子进程都可以同时写入，也都可以读出。那么，为了避免这种情况，通常的做法是：

- 父进程关闭读取的 fd[0]，只保留写入的 fd[1]；
- 子进程关闭写入的 fd[1]，只保留读取的 fd[0]；

![image-20210413160807996](E:\typora-user-images\image-20210413160807996.png)

所以说如果需要双向通信，则应该创建两个管道。

到这里，我们仅仅解析了使用管道进行父进程与子进程之间的通信，但是在我们 shell 里面并不是这样的。

在 shell 里面执行 `A | B`命令的时候，A 进程和 B 进程都是 shell 创建出来的子进程，A 和 B 之间不存在父子关系，它俩的父进程都是 shell。

![image-20210413160950296](E:\typora-user-images\image-20210413160950296.png)

所以说，在 shell 里通过「`|`」匿名管道将多个命令连接在一起，实际上也就是创建了多个子进程，那么在我们编写 shell 脚本时，能使用一个管道搞定的事情，就不要多用一个管道，这样可以减少创建子进程的系统开销。

我们可以得知，**对于匿名管道，它的通信范围是存在父子关系的进程**。因为管道没有实体，也就是没有管道文件，只能通过 fork 来复制父进程 fd 文件描述符，来达到通信的目的。

另外，**对于命名管道，它可以在不相关的进程间也能相互通信**。因为**命令管道，提前创建了一个类型为管道的设备文件**，在进程里只要使用这个**设备文件**，就可以相互通信。

不管是匿名管道还是命名管道，**进程写入的数据都是缓存在内核中**，另一个进程读取数据时候**自然也是从内核中获取**，同时通信数据都遵循**先进先出**原则，不支持 lseek 之类的文件定位操作。



### 3.消息队列**(Message Queuing)** 

消息队列是**存放在内核中的消息链表,具有特定的格式**,存放在内存中并由消息队列标识符标识。在**发送数据时，会分成一个一个独立的数据单元，也就是消息体（数据块），消息体是用户自定义的数据类型**，消息的**发送方和接收方要约定好消息体的数据类型**，所以**每个消息体都是固定大小的存储块**，不像管道是无格式的字节流数据。如果进程从消息队列中读取了消息体，内核就会把这个消息体删除。

前面说到管道的通信方式是效率低的，因此管道不适合进程间频繁地交换数据。

对于这个问题，**消息队列**的通信模式就可以解决。比如，A 进程要给 B 进程发送消息，A 进程把数据放在对应的消息队列后就可以正常返回了，B 进程需要的时候再去读取数据就可以了。同理，B 进程要给 A 进程发送消息也是如此。



消息这种模型，两个进程之间的通信就像平时发邮件一样，你来一封，我回一封，可以频繁沟通了。

但邮件的通信方式存在不足的地方有两点，**一是通信不及时，二是附件也有大小限制**，这同样也是消息队列通信不足的点。



管道和消息队列相同点：

- 管道和消息队列的通信数据都是**先进先出**的原则。

管道和消息队列不同点：

- **数据格式**：管道的数据类型是数据流而且限制大小，而消息队列是发送方和接收方约定好的数据格式也就是**固定代表的消息体**

- **生命周期不同  消息队列随内核**：与管道（生命周期随进程）（**无名管道**：只存在于**内存中的文件**；**命名管道**：存在于实际的**磁盘介质或者文件系统**）不同的是**消息队列存放在内核**中，只有在内核重启(即，操作系统重启)或者显示地删除一个消息队列时，该消息队列才会被真正的删除。
- 消息队列可以实现消息的**随机查询**,消息不一定要以先进先出的次序读取,也可以按**消息的类型读取.比 FIFO 更有优势**。**消息队列克服了信号承载信息量少，管道只能承载无格式字 节流以及缓冲区大小受限等缺。**

优点：可以实现**任意进程间的通信**，并通过系统调用函数来实现消息发送和接收之间的同步，**无需考虑同步问题，方便**；

缺点：

1. **消息队列不适合比较大数据的传输**，因为在**内核中每个消息体都有一个最大长度的限制**，同时所有**队列所包含的全部消息体的总长度也是有上限**。在 Linux 内核中，会有两个宏定义 `MSGMAX` 和 `MSGMNB`，它们以字节为单位，分别定义了一条消息的最大长度和一个队列的最大长度。

2. **消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销**，因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程。

### 4.**共享内存(Shared memory)**

消息队列的读取和写入的过程，都会有发生用户态与内核态之间的消息拷贝过程。那**共享内存**的方式，就很好的解决了这一问题。

现代操作系统，对于内存管理，采用的是虚拟内存技术，也就是每个进程都有自己独立的虚拟内存空间，不同进程的虚拟内存映射到不同的物理内存中。所以，即使进程 A 和 进程 B 的虚拟地址是一样的，其实访问的是不同的物理内存地址，对于数据的增删查改互不影响。

**共享内存的机制，就是两个需要通信的进程各拿出一块虚拟地址空间来，映射到相同的物理内存中**。这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，传来传去，大大提高了进程间通信的速度。

![image-20210413173046088](E:\typora-user-images\image-20210413173046088.png)



使得**多个进程可以访问同一块内存空间**，不同进程可以及时看到对方进程中对共享内存中数据的更新。这种方式需要依靠某种同步操作，如**互斥锁和信号量**等。可以说这是**最有用的进程间通信方式**。

优点：无须复制，**快捷**，信息量大；进程间通信最快的方式

缺点：1）通信是通过将无法实现共享空间缓冲区直接附加到进程的虚拟地址空间中来实现的，**因此进程间的读写操作的同步问题**；2)利用内存缓冲区直接交换信息，**内存的实体存在于计算机中，只能同一个计算机系统中的诸多进程共享，不方便网络通信**

就是OS在物理内存中开辟一大段缓存空间，进程直接使用地址来共享读写的。
与管道、消息队列调用API来读写不同。
因为直接读取内存中的数据，所以共享内存的通信方式快
而管道、消息队列的通信方式慢

![在这里插入图片描述](https://img-blog.csdnimg.cn/20191030112116766.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTA5NzMxMg==,size_16,color_FFFFFF,t_70)

#### 共享内存的实现方式：

以两个进程使用共享内存来通信为例：
1、调用API，让OS在物理内存上开辟出一大段缓存空间
2、让各自进程空间与开辟出的缓存空间建立映射关系

建立了映射关系后，每个进程都可以通过映射后的虚拟地址来共享操作实现通信了

#### 共享内存存在的问题 要进行同步操作

当实现多个进程映射到同一片空间进行数据共享时，在写数据时就会出现互相干扰。

比如A进程写一半时切到B进程造成A的数据被打断。因为CPU都是不停的在不同进程之间切换运行，每个进程都有自己的时间片，本来A进程被打断后，等下次重新恢复运行时继续在自己内存上写数据，但是因为和B进程共享内存，导致在A打断期间运行B时也写入了数据，也是写入到与A的共享内存上，等恢复A运行时，其内存上已经写入了其他数据（B写入的）。这样就造成数据的错误。

这就需要加保护措施，这里先不对此详细叙述


### 5.信号量

用了共享内存通信方式，带来新的问题，那就是如果多个进程同时修改同一个共享内存，很有可能就冲突了。例如两个进程都同时写一个地址，那先写的那个进程会发现内容被别人覆盖了。

为了防止多进程竞争共享资源，而造成的数据错乱，所以需要保护机制，使得共享的资源，在任意时刻只能被一个进程访问。正好，**信号量**就实现了这一保护机制。



**信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据**。

信号量表示资源的数量，控制信号量的方式有两种原子操作：

- 一个是 **P 操作**，这个操作会把信号量减去 -1，相减后如果信号量 < 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 >= 0，则表明还有资源可使用，进程可正常继续执行。
- 另一个是 **V 操作**，这个操作会把信号量加上 1，相加后如果信号量 <= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 > 0，则表明当前没有阻塞中的进程；

**P 操作是用在进入共享资源之前，V 操作是用在离开共享资源之后，这两个操作是必须成对出现的**。

接下来，举个例子，如果要使得两个进程互斥访问共享内存，我们可以初始化信号量为 `1`。

![image-20210413173841516](E:\typora-user-images\image-20210413173841516.png)





具体的过程如下：

- 进程 A 在访问共享内存前，先执行了 P 操作，由于信号量的初始值为 1，故在进程 A 执行 P 操作后信号量变为 0，表示共享资源可用，于是进程 A 就可以访问共享内存。
- 若此时，进程 B 也想访问共享内存，执行了 P 操作，结果信号量变为了 -1，这就意味着临界资源已被占用，因此进程 B 被阻塞。
- 直到进程 A 访问完共享内存，才会执行 V 操作，使得信号量恢复为 0，接着就会唤醒阻塞中的线程 B，使得进程 B 可以访问共享内存，最后完成共享内存的访问后，执行 V 操作，使信号量恢复到初始值 1。

可以发现，信号初始化为 `1`，就代表着是**互斥信号量**，它可以保证共享内存在任何时刻只有一个进程在访问，这就很好的保护了共享内存

还可以实现生产者和消费者机制

例如，进程 A 是负责生产数据，而进程 B 是负责读取数据，这两个进程是相互合作、相互依赖的，进程 A 必须先生产了数据，进程 B 才能读取到数据，所以执行是有前后顺序的。

那么这时候，就可以用信号量来实现多进程同步的方式，我们可以初始化信号量为`0`。

![image-20210413174250908](E:\typora-user-images\image-20210413174250908.png)

具体过程：

- 如果进程 B 比进程 A 先执行了，那么执行到 P 操作时，由于信号量初始值为 0，故信号量会变为 -1，表示进程 A 还没生产数据，于是进程 B 就阻塞等待；
- 接着，当进程 A 生产完数据后，执行了 V 操作，就会使得信号量变为 0，于是就会唤醒阻塞在 P 操作的进程 B；
- 最后，进程 B 被唤醒后，意味着进程 A 已经生产了数据，于是进程 B 就可以正常读取数据了。

可以发现，信号初始化为 `0`，就代表着是**同步信号量**，它可以保证进程 A 应在进程 B 之前执行。







### 6.信号**(Signal)** ：

在 Linux 操作系统中， 为了响应各种各样的事件，提供了几十种信号，分别代表不同的意义。我们可以通过 `kill -l` 命令，查看所有的信号：

```
$ kill -l
 1) SIGHUP       2) SIGINT       3) SIGQUIT      4) SIGILL       5) SIGTRAP
 6) SIGABRT      7) SIGBUS       8) SIGFPE       9) SIGKILL     10) SIGUSR1
11) SIGSEGV     12) SIGUSR2     13) SIGPIPE     14) SIGALRM     15) SIGTERM
16) SIGSTKFLT   17) SIGCHLD     18) SIGCONT     19) SIGSTOP     20) SIGTSTP
21) SIGTTIN     22) SIGTTOU     23) SIGURG      24) SIGXCPU     25) SIGXFSZ
26) SIGVTALRM   27) SIGPROF     28) SIGWINCH    29) SIGIO       30) SIGPWR
31) SIGSYS      34) SIGRTMIN    35) SIGRTMIN+1  36) SIGRTMIN+2  37) SIGRTMIN+3
38) SIGRTMIN+4  39) SIGRTMIN+5  40) SIGRTMIN+6  41) SIGRTMIN+7  42) SIGRTMIN+8
43) SIGRTMIN+9  44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+13
48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-12
53) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9  56) SIGRTMAX-8  57) SIGRTMAX-7
58) SIGRTMAX-6  59) SIGRTMAX-5  60) SIGRTMAX-4  61) SIGRTMAX-3  62) SIGRTMAX-2
63) SIGRTMAX-1  64) SIGRTMAX
```

运行在 shell 终端的进程，我们可以通过键盘输入某些组合键的时候，给进程发送信号。例如

- Ctrl+C 产生 `SIGINT` 信号，表示终止该进程；
- Ctrl+Z 产生 `SIGTSTP` 信号，表示停止该进程，但还未结束；

如果进程在后台运行，可以通过 `kill` 命令的方式给进程发送信号，但前提需要知道运行中的进程 PID 号，例如：

- kill -9 1050 ，表示给 PID 为 1050 的进程发送 `SIGKILL` 信号，用来立即结束该进程；

所以，信号事件的来源主要有**硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令）**。

信号是进程间通信机制中**唯一的异步通信机制**，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户**进程对信号的处理方**式。

**1.执行默认操作**。Linux 对每种信号都规定了默认操作，例如，上面列表中的 SIGTERM 信号，就是终止进程的意思。Core 的意思是 Core Dump，也即终止进程后，通过 Core Dump 将当前进程的运行状态保存在文件里面，方便程序员事后进行分析问题在哪里。

**2.捕捉信号**。我们可以**为信号定义一个信号处理函数**。当信号发生时，我们就执行相应的信号处理函数。

**3.忽略信号**。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应用进程无法捕捉和忽略的，即 `SIGKILL` 和 `SEGSTOP`，它们用于在任何时候中断或结束某一进程。









信号是Linux系统中**用于进程间互相通信或者操作的一种机制**，信号可以在**任何时候发给某一进程，而无需知道该进程的状态**。
 如果该进程当前并未处于执行状态，则该信号就由**内核保存**起来，直到该进程回复执行并传递给它为止。
 如果一个信号被进程设置为阻塞，则该信号的传递被延迟，直到其阻塞被取消是才被传递给进程。



| 信号    | 描述                                                         |
| ------- | ------------------------------------------------------------ |
| SIGUP   | 当用户退出终端时，由该终端开启的所有进程都退接收到这个信号，默认动作为终止进程。 |
| SIGINT  | 程序终止(interrupt)信号, 在用户键入INTR字符(通常是Ctrl+C)时发出，用于通知前台进程组终止进程。 |
| SIGQUIT | 和SIGINT类似, 但由QUIT字符(通常是Ctrl+)来控制. 进程在因收到SIGQUIT退出时会产生core文件, 在这个意义上类似于一个程序错误信号。 |
| SIGKILL | 用来立即结束程序的运行. 本信号不能被阻塞、处理和忽略。       |
| SIGTERM | 程序结束(terminate)信号, 与SIGKILL不同的是该信号可以被阻塞和处理。通常用来要求程序自己正常退出。 |
| SIGSTOP | 停止(stopped)进程的执行. 注意它和terminate以及interrupt的区别:该进程还未结束, 只是暂停执行. 本信号不能被阻塞, 处理或忽略. |



### 7.**套接字(Sockets)** ：

前面提到的管道、消息队列、共享内存、信号量和信号都是在同一主机上进行进程间通信的，那要想**跨网络与不同主机上的进程之间通信，就需要 Socket 通信了。**

实际上，Socket 通信不仅可以跨网络与不同主机的进程间通信，还可以在同主机上进程间通信。

我们来看看创建 socket 的系统调用：

```
int socket(int domain, int type, int protocal)
```

三个参数分别代表：

- domain 参数用来指定协议族，比如 AF_INET 用于 IPV4、AF_INET6 用于 IPV6、AF_LOCAL/AF_UNIX 用于本机；
- type 参数用来指定**通信特性**，比如**SOCK_STREAM 表示的是字节流，对应 TCP**、S**OCK_DGRAM  表示的是数据报，对应 UDP、SOCK_RAW 表示的是原始套接字；**
- protocal 参数原本是用来指定通信协议的，但现在基本废弃。因为协议已经通过前面两个参数指定完成，protocol 目前一般写成 0 即可；



根据创建 socket 类型的不同，通信的方式也就不同：

- 实现 TCP 字节流通信：socket 类型是 AF_INET 和 SOCK_STREAM；
- 实现 UDP 数据报通信：socket 类型是 AF_INET 和 SOCK_DGRAM；
- 实现本地进程间通信：「本地字节流 socket 」类型是 AF_LOCAL 和 SOCK_STREAM，「本地数据报 socket 」类型是 AF_LOCAL 和 SOCK_DGRAM。另外，AF_UNIX 和 AF_LOCAL 是等价的，所以 AF_UNIX 也属于本地 socket；





此方法主要用于在**客户端和服务器之间通过网络进行通信**。套接字是支持TCP/IP的网络的基本操作单元，**可以看做是不同主机之间的进程的双向通信的端点**。简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。

![在这里插入图片描述](https://uploadfiles.nowcoder.com/files/20210405/36237626_1617615699151/2021040515432596.png)



接下来，简单说一下这三种通信的编程模式。

> 针对 TCP 协议通信的 socket 编程模型

![image-20210413194253344](E:\typora-user-images\image-20210413194253344.png)

- 服务端和客户端初始化 `socket`，得到文件描述符；
- 服务端调用 `bind`，将socket绑定在 IP 地址和端口;
- 服务端调用 `listen`，进行监听；
- 服务端调用 `accept`，等待客户端连接；
- 客户端调用 `connect`，向服务器端的地址和端口发起连接请求；（三次握手成功 从全连接队列中由accpet()函数取出）
- 服务端 `accept` **返回用于传输的 `socket` 的文件描述符**；
- 客户端调用 `write` 写入数据；服务端调用 `read` 读取数据；
- 客户端断开连接时，会调用 `close`，那么服务端 `read` 读取数据的时候，就会读取到了 `EOF`，待处理完数据后，服务端调用 `close`，表示连接关闭。

这里需要注意的是，服务端调用 `accept` 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。

所以，监听的 socket 和真正用来传送数据的 socket，是「**两个**」 socket，一个叫作**监听 socket**，一个叫作**已完成连接 socket**。

成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。



>  针对 UDP 协议通信的 socket 编程模型

![image-20210413194619088](E:\typora-user-images\image-20210413194619088.png)

UDP 是没有连接的，所以不需要三次握手，**也就不需要像 TCP 调用 listen 和 connect**，但是 **UDP 的交互仍然需要 IP 地址和端口号，因此也需要 bind**。

对于 UDP 来说，不需要要维护连接，那么也就没有所谓的发送方和接收方，甚至都不存在客户端和服务端的概念，只要有一个 socket 多台机器就可以任意通信，因此每一个 UDP 的 socket 都需要 bind。

另外，每次通信时，调用 sendto 和 recvfrom，都要传入目标主机的 IP 地址和端口。



> 针对本地进程间通信的 socket 编程模型

本地 socket  被用于在**同一台主机上进程间通信**的场景：

- 本地 socket 的编程接口和 IPv4 、IPv6 套接字编程接口是一致的，可以支持「字节流」和「数据报」两种协议；
- 本地 socket 的实现效率大大高于 IPv4 和 IPv6 的字节流、数据报 socket 实现；

对于本地字节流 socket，其 socket 类型是 AF_LOCAL 和 SOCK_STREAM。

对于本地数据报 socket，其 socket 类型是 AF_LOCAL 和 SOCK_DGRAM。

本地字节流 socket 和 本地数据报 socket 在 bind 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端口，而是**绑定一个本地文件**，这也就是它们之间的最大区别。



优点：1）传输数据为**字节级**，传输数据可自定义，**数据量小效率高**；2）传输数据**时间短，性能高**；3) 适合于客户端和服务器端之间信息实时交互；4) 可以加密,数据安全性强
缺点：1) 需对传输的数据进行解析，转化成应用级的数据



### 总结：

由于每个进程的用户空间都是独立的，不能相互访问，这时就需要借助内核空间来实现进程间通信，原因很简单，每个进程都是共享一个内核空间。

Linux 内核提供了不少进程间通信的方式，其中最简单的方式就是管道，管道分为「匿名管道」和「命名管道」。

**匿名管道**顾名思义，它没有名字标识，匿名管道是特殊文件只存在于内存，没有存在于文件系统中，shell 命令中的「`|`」竖线就是匿名管道，通信的数据是**无格式的流并且大小受限**，通信的方式是**单向**的，数据只能在一个方向上流动，如果要双向通信，需要创建两个管道，再来**匿名管道是只能用于存在父子关系的进程间通信**，匿名管道的生命周期随着进程创建而建立，随着进程终止而消失。

**命名管道**突破了匿名管道只能在亲缘关系进程间的通信限制，因为使用命名管道的前提，**需要在文件系统创建一个类型为 p 的设备文件**，那么毫无关系的进程就可以通过这个设备文件进行通信。另外，不管是匿名管道还是命名管道，进程写入的数据都是**缓存在内核**中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循**先进先出**原则，不支持 lseek 之类的文件定位操作。

**消息队列**克服了**管道通信的数据是无格式的字节流的问题，消息队列实际上是保存在内核的「消息链表」**，消息队列的消息体是可以用户自定义的数据类型，发送数据时，会被分成一个一个独立的消息体，当然接收数据时，也要与发送方发送的消息体的数据类型保持一致，这样才能保证读取的数据是正确的。消息队列通信的速度不是最及时的，毕竟**每次数据的写入和读取都需要经过用户态与内核态之间的拷贝过程。**

**共享内存**可以解决消息队列通信中用户态与内核态之间数据拷贝过程带来的开销，**它直接分配一个共享空间，每个进程都可以直接访问**，就像访问进程自己的空间一样快捷方便，不需要陷入内核态或者系统调用，大大提高了通信的速度，享有**最快**的进程间通信方式之名。但是便捷高效的共享内存通信，**带来新的问题，多进程竞争同个共享资源会造成数据的错乱。**

那么，就需要**信号量**来保护共享资源，以确保任何时刻只能有一个进程访问共享资源，这种方式就是互斥访问。**信号量不仅可以实现访问的互斥性，还可以实现进程间的同步**，信号量其实是一个计数器，表示的是资源个数，其值可以通过两个原子操作来控制，分别是 **P 操作和 V 操作**。

与信号量名字很相似的叫**信号**，它俩名字虽然相似，但功能一点儿都不一样。信号是进程间通信机制中**唯一的异步通信机制**，信号可以在应用进程和内核之间直接交互，内核也可以利用信号来通知用户空间的进程发生了哪些系统事件，信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令），一旦有信号发生，**进程有三种方式响应信号 1. 执行默认操作、2. 捕捉信号、3. 忽略信号**。有两个信号是应用进程无法捕捉和忽略的，即 `SIGKILL` 和 `SEGSTOP`，这是为了方便我们能在任何时候结束或停止某个进程。

前面说到的通信机制，都是工作于同一台主机，如果**要与不同主机的进程间通信，那么就需要 Socket 通信了**。Socket 实际上不仅用于不同的主机进程间通信，还可以用于本地主机进程间通信，可根据创建 Socket 的类型不同，分为三种常见的通信方式，一个是基于 TCP 协议的通信方式，一个是基于 UDP 协议的通信方式，一个是本地进程间通信方式。

以上，就是进程间通信的主要机制了。你可能会问了，那线程通信间的方式呢？

同个进程下的线程之间都是共享进程的资源，只要是共享变量都可以做到线程间通信，比如全局变量，所以对于线程间关注的不是通信方式，而是关注多线程竞争共享资源的问题，信号量也同样可以在线程间实现互斥与同步：

- 互斥的方式，可保证任意时刻只有一个线程访问共享资源；
- 同步的方式，可保证线程 A 应在线程 B 之前执行

## 4.1匿名管道和管道的区别和相同点：

相同点：数据都是缓存在**内核中**的字节流，管道和匿名管道都是存了管道文件的描述符

区别：匿名管道是父进程fork出一个子进程，然后在父子进程之间通信，也就是只有父子进程知道这个管道的位置，拿得到这个fd。这保证了传输数据的安全性，当然也降低了管道了通用性

而是p类型。表示这是一个管道文件。有了这个管道文件，系统中就有了对一个管道的全局名称，于是任何两个不相关的进程都可以通过这个管道文件进行通信了。

**无名管道**：只存在于**内存中的文件**；**命名管道**：存在于实际的**磁盘介质或者文件系统**

4.1.1匿名管道和管道对应的linux的系统调用函数返回值,参数

使用pipe()系统调用可以创建一个匿名管道，这个系统调用的原型为：

```c
int pipe(int pipefd[2]);
```

这个方法将会创建出两个文件描述符，可以使用pipefd这个数组来引用这两个描述符进行文件操作



### 哪种IPC速度最快？为什么？

共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。因为本身就是不同的虚拟地址映射到同一块物理地址上 









## 5.线程同步(通信)的方式有哪些？

线程间通信：同一进程内的多线程之间通信因为共享相同的地址空间，所以更多的是处理线程间的同步问题。

不同进程间的线程之间通信则类似进程间通信的方式。 socket 管道 消息队列  wait/notify 

线程间同步：互斥锁，条件变量，读写锁，信号量等。



![image-20211024231639381](E:\TyporaPic\image-20211024231639381.png)





线程同步是两个或多个共享关键资源的线程的并发执行.应该同步线程以避免关键的资源使用冲突。

OS有三种方式：

1. 临界区（Critical Section）：**适合一个进程内的多线程**访问公共区域或代码段时使用
2. 互斥量 (Mutex)：适合**不同进程内多线程**访问公共区域或代码段时使用，与临界区相似。
3. 信号量（Semaphore）：与临界区和互斥量不同，可以实现多个线程同时访问公共区域数据。可以跨进程使用。原理与操作系统中PV操作类似，**先设置一个访问公共区域的线程最大连接数，每有一个线程访问共享区资源数就减一，直到资源数小于等于零**。
4. 事件（Event）：通过线程间触发事件实现同步互斥  实现同步 等待 通知机制

## 6.进程的调度种类、算法有哪些？

**调度种类**

- **高级调度**：(High-Level Scheduling)又称为**作业调度**，它决定把后备作业调入内存运行
- **低级调度**：(Low-Level Scheduling)又称为**进程调度**，它决定把就绪队列的某进程获得CPU
- **中级调度**：(Intermediate-Level Scheduling)又称为在**虚拟存储器**中引入，在**内、外存对换区进行进程对换**

**非抢占式调度与抢占式调度**

- **非抢占式**：分派程序一旦把处理机分配给某进程后便让它一直运行下去，直到进程完成或发生进程调度进程调度某事件而阻塞时，才把处理机分配给另一个进程
- **抢占式**：操作系统将正在运行的进程强行暂停，由调度程序将CPU分配给其他就绪进程的调度方式



1. 先来先服务(FCFS):从就绪队列中选择一个最先进入该队列的进程为之分配资源，使它立即执行并一直**执行到完成**或发**生某事件而被阻塞**放弃占用 CPU 时再重新调度。

- 优点：简单，理解容易
- 缺点：进程平均等待时间长，假设一组进程(P1, P2, P3)，所需时间(24, 3, 3), CPU执行长度按ms记，按照FCFS算法，执行顺序为(P1, P2, P3)则平均等待时间为 (0 + 24 + 27) / 3 = 17ms，如果执行顺序为(P2, P3, P1), 则平均等待时间为(0 + 3 + 6) / 3 = 3ms，这个减少是相当大的。

2. 短作业优先(SJF)：从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。

- 优点：如果能够实现将是最优的。
- 缺点：这个算法有一个附加的问题，就是如何准确地知道每个进程所需要的时间，这是很困难的，所以SJF算法经常用于长期调度，将用户提交作业时指定的进程时限作为长度。

3. 时间片轮转调度算法(RR)：又称 RR(Round robin)调度。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。

4. 高响应比优先算法：R=(w+s)/s （R为响应比，w为等待处理的时间，s为预计的服务时间）选择响应比最高的

5. 多级反馈队列调度算法：前面介绍的几种进程调度的算法都有一定的局限性。如**短进程优先的调度算法，仅照顾了短进程而忽略了长进程** 。多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。，因而它是目前**被公认的一种较好的进程调度算法**，**UNIX 操作系统采取的便是这种调度算法**。

6. 优先级：为每个流程**分配优先级**，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。

   问题：题是可能导致**无限阻塞**或**饥饿**

> 多级反馈队列调度算法:
>
> 1.设置多个就绪队列，并且为各个队列设置不同的优先级，在优先权越高的队列中，为每个进程所规定的执行时间片就越小。
>
> 2.当进程进入队列后，先进入第一个队列的队尾，按照先来先服务的原则排队等候调度。如果他能在一个时间片中完成，便可撤离；如果未完成，就转入第二队列的末尾，同样等待调度.....如此下去，当一个长作业（进程）从第一队列依次将到第n队列（最后队列）后，便按第n队列时间片轮转运行。
>
> 3.紧当第一队列空闲时，调度队列才调度第二队列中的进程运行；仅当第1到（i-1）队列空时，才会调度第i队列中的进程运行，并执行相应的时间片轮转。
>
> 4.如果处理机正在处理第i队列中某进程，又有新进程进入优先权较高的队列，则此新队列抢占正在运行的处理机，并把正在运行的进程放在第i队列的队尾。
>
> 缺点：抢占式，可能导致饥饿



## 6.1linux中进程是如何调度的

在进行调度时,linux将进程分为普通进程和实时进程

#### 普通进程

在 Linux 中普通进程依赖称之为 nice 值 的东东来进行进程的优先级描述。nice 值的范围是 [-20, 19]。默认的 default 值为 0；越低的 nice 值，代表着越高的优先级，反之，越高的 nice 值代表着越低的优先级。

越高优先级的 普通进程 有着越高的执行时间（注意，这里值的越高的执行时间，指的是在一小段观察时间内，每个可执行的进程都执行一遍的情况，这里的描述可能产生一些歧义，稍安勿躁，接着看）



#### 实时进程

实时优先级是可配置value值的默认情况下的范围是 0~99，与 nice 值相反，越高的实时优先级数值代表着越高的优先级。与此同时，***\*任何实时进程的优先级都高于普通进程的优先级\****。

#### 总结：

实时进程优先级：value 越高，优先级越大

普通进程优先级：nice值越高，普通进程的优先级越小

任何实时进程的优先级 > 普通进程



linux调度算法：

Linux 中有一个总的调度结构，称之为 **调度器类**（scheduler class），它允许不同的可动态添加的调度算法并存，**总调度器根据调度器类的优先顺序**，依次去进行调度器类的中的进程进行调度，挑选了调度器类，再在这个调度器内，使用这个调度器类的算法（调度策略）进行内部的调度

![img](https://img-blog.csdnimg.cn/20190111175827198.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pob3V0YW9wb3dlcg==,size_16,color_FFFFFF,t_70)



调度器的优先级顺序为：

Scheduling Class 的优先级顺序为 Stop_ask > Real_Time > Fair > Idle_Task,开发者可以根据己的设计需求,來把所属的Task配置到不同的Scheduling Class中。其中的 Real_time 和 Fair 是最最常用的，下面主要聊聊着两类。



### 一、Fair 调度使用的是 ***CFS*** 的调度算法，即**完全公平调度器**（普通进程，优先级体现在分配的时间上 而调度选择上没有体现）

对于一个普通进程，CFS 调度器调度它执行（**SCHED_NORMAL**），需要考虑两个方面维度：

CFS 调度程序没有直接分配优先级。相反，**它通过每个任务的变量 vruntime 以便维护虚拟运行时间，进而记录每个任务运行多久。虚拟运行时间与基于任务优先级的衰减因子有关，更低优先级的任务比更高优先级的任务具有更高衰减速率**。对于正常优先级的任务（友好值为 0），虚拟运行时间与实际物理运行时间是相同的。

因此，如果一个默认优先级的任务运行 200ms，则它的虚拟运行时间也为 200ms。然而，如果一个较低优先级的任务运行 200ms，则它的虚拟运行时间将大于 200ms。同样，如果一个更高优先级的任务运行 200ms，则它的虚拟运行时间将小于 200ms。当决定下步运行哪个任务时，调度程序只需选择具有最小虚拟运行时间的任务。此外，一个更高优先级的任务如成为可运行，就会抢占低优先级任务。





### 二、实时调度策略

对于实时调度策略分为两种：SCHED_FIFO 和 SCHED_RR：

这两种进程都比任何普通进程的优先级更高（SCHED_NORMAL），都会比他们更先得到调度。



SCHED_FIFO ： 一个这种类型的进程出于可执行的状态，就会一直执行，直到它自己被阻塞或者主动放弃 CPU；它不基于时间片，可以一直执行下去，只有更高优先级的 SCHED_FIFO 或者 SCHED_RR 才能抢占它的任务，如果有两个同样优先级的 SCHED_FIFO 任务，它们会轮流执行，其他低优先级的只有等它们变为不可执行状态，才有机会执行。

SCHED_RR ： 与 SCHED_FIFO 大致相同，只是 SCHED_RR 级的进程在耗尽其时间后，不能再执行，需要接受 CPU 的调度。当 SCHED_RR 耗尽时间后，同一优先级的其他实时进程被轮流调度。

优先级都是静态设定的







\- 调度策略与调度类
\- 进程包括两类: 实时进程(优先级高); 普通进程
\- 两种进程调度策略不同: task_struct->policy 指明采用哪种调度策略(有6种策略)
\- 优先级配合调度策略, 实时进程(0-99); 普通进程(100-139)
\- **实时调度策略**, 高优先级可抢占低优先级进程
\- FIFO: 相同优先级进程先来先得
\- RR: 轮流调度策略, 采用时间片轮流调度相同优先级进程
\- Deadline: 在调度时, 选择 deadline 最近的进程
\- **普通调度策略**
\- normal: 普通进程
\- batch: 后台进程, 可以降低优先级
\- idle: 空闲时才运行
\- 调度类: task_struct 中 * sched_class 指向封装了调度策略执行逻辑的类(有5种)
\- stop: 优先级最高. 将中断其他所有进程, 且不能被打断
\- dl: 实现 deadline 调度策略
\- rt: RR 或 FIFO, 具体策略由 task_struct->policy 指定
\- fair: 普通进程调度
\- idle: 空闲进程调度
\- 普通进程的 fair 完全公平调度算法 CFS(Linux 实现)
\- 记录进程运行时间( vruntime 虚拟运行时间)
\- 优先调度 vruntime 小的进程
\- 按照比例累计 vruntime, 使之考虑进优先级关系
\- 调度队列和调度实体
\- CFS 中需要对 vruntime 排序找最小, 不断查询更新, 因此利用红黑树实现调度队列
\- task_struct 中有 实时, deadline 和 cfs 三个调度实体, cfs 调度实体即红黑树节点
\- 每个 CPU 都有 rq 结构体, 里面有 dl_rq, rt_rq 和 cfs_rq 三个调度队列以及其他信息; 队列描述该 CPU 所运行的所有进程
\- **先在 rt_rq 中找进程运行, 若没有再到 cfs_rq 中找; cfs_rq 中 rb_root 指向红黑树根节点, rb_leftmost指向最左节点**
\- 调度类如何工作
\- 调度类中有一个成员指向下一个调度类(按优先级顺序串起来)
\- 找下一个运行任务时, 按 stop-dl-rt-fair-idle 依次调用调度类, 不同调度类操作不同调度队列







## 二、内存管理



## 7.内存管理主要做什么？

 操作系统的内存管理主要负责**内存的分配与回收**（malloc 函数：申请内存，free 函数：释放内存），另外**地址转换**也就是将**逻辑地址转换成相应的物理地址**等功能也是操作系统内存管理做的事情。



## 8.**操作系统的内存管理机制了解吗？内存管理有哪几种方式?**

内存管理分为：**连续分配**和**非连续分配**管理方式

连续分配：连续分配管理方式是指为一个用户程序分配一个连续的内存空间

> 内部碎片：是一个分区中的碎片
>
> 外部碎片：分区与分区之间的碎片 可以通过紧凑技术解决

1. 单一连续分配：内存分为**系统区和用户区**，系统区进提供os使用，通常低地址部分，用户去给用户提供

   优点：简单、无外部碎片

   缺点：只能用于单任务、单用户的os 且有内部碎片

2. 固定分区分配：将内存**划分为若干固定大小的区域**，每个分区只装一道作业

   固定分区有两种方法：一种是分区大小相等的分配方法（缺乏灵活性），另一种是分区大小不等

3. 动态分区分配：动态划分内存的方法，分区的大小和数目是可变的

   分配策略有：

   1. 首次适应：空闲分区以**地址递增**的次序连接，分配时**从头顺序查找**，找到第一个能满足要求的分区
   2. 最佳适应：分区按**容量递增**的方式连接，找到第一个能满足要求的分区，优点：保留大空间，缺点：产生外部碎片
   3. 最坏适应：分区按**容量递减**的方式连接，又叫最大时应，挑选出最大分区  缺点：大空间被迅速用完
   4. 临近适应：和首次适应一样，都是按照**地址递增**的次序连接，但是分配内存时，从上一次**查找结束的位置**开始继续查找

   

非连续分配：允许一个程序使用的内存分布在离散或者说不相邻的内存中

1. 页式管理：把主存分为大小相等且固定的一页一页的形式，页较小，提高了内存利用率，一般去2的整数幂，页式管理**通过页表对应逻辑地址和物理地址**。

   页面如果太大，就会产生页内碎片，页面如果太小，就会使页表过长，占用太多空间，因此需要权衡

2. 段式管理：分页管理是从计算机的角度考虑设计的，目的是提高**内存利用率，提升性能，分页通过硬件实现**，对用户完全透明，分段则是为了**用户和程序员考虑的**，以方便编程 信息保护、共享 动态增长和连接等多方面需求，段式管理把主存分为一段段的，**每一段的空间又要比一页的空间小很**多 。但是，最重要的是**段是有实际意义**的，每个段定义了一组逻辑信息，例如,有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。 段式管理**通过段表对应逻辑地址和物理地址**。

3. 段页式管理：段页式管理机制**结合了段式管理和页式管理的优点**。简单来说段页式管理机制就是把主存**先分成若干段**，**每个段又分成若干页**，也就是说 **段页式管理机制** 中**段与段之间以及段的内部的都是离散**的。





## 9.快表和多级页表

### 9.1快表

为了解决虚拟地址到物理地址的转换速度，操作系统在 **页表方案** 基础之上引入了 **快表** 来加速虚拟地址到物理地址的转换。我们可以把快表理解为一种特殊的**高速缓冲存储器（Cache）**，其中的内容是页表的一部分或者全部内容。作为页表的 Cache，它的作用与页表相似，但是提高了访问速率。由于采用页表做地址转换，读写内存数据时 CPU 要访问两次主存。有了快表，有时只要访问**一次高速缓冲存储器，一次主存，这样可加速查找**并提高指令执行速度。

使用快表之后的地址转换流程是这样的：

1. 根据虚拟地址中的页号查询快表
2. 如果该页在快表中，直接从快表中读取相应的物理地址；
3. 如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，**同时将页表中的该映射表项添加到快表中**；
4. 当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。

#### 多级页表

引入多级页表的主要**目的是为了避免把全部页表一直放在内存中占用过多空间**，特别是那些根本就不需要的页表就不需要保留在内存中。多级页表属于**时间换空间**的典型场景，具体可以查看下面这篇文章

才能够一级页表中查询二级页表的页号，才从二级页表中查出页号

将逻辑地址分为：

一级页号 二级页号 页内偏移

#### 总结

为了提高内存的空间性能，提出了多级页表的概念；但是提到空间性能是以浪费时间性能为基础的，因此为了补充损失的时间性能，提出了快表（即 TLB）的概念。 不论是快表还是**多级页表实际上**都利用到了程序的**局部性原理**，局部性原理在后面的虚拟内存这部分会介绍到。

## 10.分页机制和分段机制的共同点和区别 共同点 提高内存利用率 减少内存碎片 不同点 页的大小固定 段大小不固定 由当前与逆行的程序

共同点：

- 分页和分段都是为了提高内存利用率，减少内存碎片
- 页和段都是**离散存储**的，所以者都是离散分配内存的方式，但是，**每个页和段中的内存是连续的**。

不同点：

- 页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们**当前运行的程序**（）一个函数可能放在一块。
- **分页**仅仅是为了**满足操作系统内存管理**的需求，而**段是逻辑信息的单位**，在程序中可以体现为**代码段，数据段**，能够**更好满足用户的需要**。

## 11.逻辑(虚拟)地址和物理地址

**逻辑地址由操作系统决定**，**利用地址变换机构（段表、页表**）

**物理地址指的是真实物理内存中地址**，更具体一点来说就是内存地址寄存器中的地址

物理地址是内存单元真正的地址。



## 12.CPU 寻址了解吗?为什么需要虚拟地址空间?

现代处理器使用的是一种称为 **虚拟寻址(Virtual Addressing)** 的寻址方式。**使用虚拟寻址，CPU 需要将虚拟地址翻译成物理地址，这样才能访问到真实的物理内存。** 实际上完成虚拟地址转换为物理地址转换的硬件是 CPU 中含有一个被称为 **内存管理单元（Memory Management Unit, MMU）** 的硬件。如下图所示：

![image-20210311231220010](E:\typora-user-images\image-20210311231220010.png)



**为什么要有虚拟地址空间呢？**

先从没有虚拟地址空间的时候说起吧！没有虚拟地址空间的时候，**程序都是直接访问和操作的都是物理内存** 。但是这样有什么问题呢？

1. 用户程序**可以访问任意内存**，寻址内存的每个字节，这样就很容易（有意或者无意）**破坏操作系统，造成操作系统崩溃**。
2. 想要同时**运行多个程序特别困难（空间不够，一个程序覆盖另一个程序的空间）**，比如你想同时运行一个微信和一个 QQ 音乐都不行。为什么呢？举个简单的例子：微信在运行的时候给内存地址 1xxx 赋值后，QQ 音乐也同样给内存地址 1xxx 赋值，那么 QQ 音乐对内存的赋值就会覆盖微信之前所赋的值，这就造成了微信这个程序就会崩溃。

**总结来说**：如果直接把物理地址暴露出来的话会带来严重问题，**比如可能对操作系统造成伤害以及给同时运行多个程序造成困难。**

通过虚拟地址访问内存有以下**优势**：

- 程序可以使用**一系列相邻的虚拟地址**来访问**物理内存中不相邻的大内存缓冲区**。

- 程序可以使用一系列虚拟地址来访问**大于可用物理内存的内存缓冲区**。当物理内存的供应量变小时，内存管理器**会将物理内存页（通常大小为 4 KB）保存到磁盘文件**。**数据或代码页**会根据需要在**物理内存与磁盘**之间移动。

- **不同进程使用的虚拟地址彼此隔离**。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。

  

## 13.什么是虚拟内存(Virtual Memory)?

简单来说就是将**程序的异步的装入内存**，另一部分留在外存（磁盘），当要访问的信息不在内存时，OS会将所需的部分调入内存，另一方面os将暂时不需要的内容换到外存上，从而腾出空间放入需要调入内存的信息，这样，OS好像为用户提供了一个比实际实际内存大得多的存储器。

系统提供了 **部分装入 请求调入 置换功能**

有以下三个特征：

1. 多次性：分多次装入
2. 对换性：无需在作业运行时的长柱内存。不需要时可以调出。
3. 虚拟性 逻辑上扩充了容量



正是因为 **虚拟内存** 的存在，通过 **虚拟内存** 可以让程序可以拥有超过系统物理内存大小的可用内存空间。另外，**虚拟内存为每个进程提供了一个一致的、私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉（每个进程拥有一片连续完整的内存空间）**。这样会更加有效地管理内存并减少出错。

**虚拟内存**是计算机系统内存管理的一种技术，我们可以手动设置自己电脑的虚拟内存。不要单纯认为虚拟内存只是“使用硬盘空间来扩展内存“的技术。**虚拟内存的重要意义是它定义了一个连续的虚拟地址空间**，并且 **把内存扩展到硬盘空间**

### 13.1虚拟内存的技术实现和需要的支持

技术实现：**虚拟内存的实现需要建立在离散分配的内存管理方式的基础上。** 虚拟内存的实现有以下三种方式：

1. **请求分页存储管理** ：建立在**分页管理**之上，为了**支持虚拟存储器功能**而增加了**请求调页功能和页面置换**功能。请求分页是目前最常用的一种实现虚拟存储器的方法。请求分页存储管理系统中，在作业开始运行之前，仅装入当前要执行的部分段即可运行。假如在作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存，同时操作系统也可以将暂时不用的页面置换到外存中。
2. **请求分段存储管理** ：建立在**分段存储**管理之上，增加了**请求调段功能、分段置换功能**。请求分段储存管理方式就如同请求分页储存管理方式一样，在作业开始运行之前，仅装入当前要执行的部分段即可运行；在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的程序段；当内存空间已满，而又需要装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段。
3. **请求段页式存储管理**

需要的支持

1. 内存、外存
2. 页表机制
3. 中断机构 ：需要调入内存时 则差生中断
4. 地址变换机构：MMU内存管理单元 逻辑地址到物理地址的变换

### 13.2局部性原理

局部性原理是虚拟内存技术的基础，正是因为程序运行具有局部性原理，才可以只装入部分程序到内存就开始运行。

局部性原理表现在以下两个方面：

1. **时间局部性** ：如果程序中的**某条指令一旦执行**，不**久以后该指令可能再次执行**；如果**某数据被访问过**，**不久以后该数据可能再次被访问**。产生时间局部性的**典型原因**，是由于在程序中存在着大量的**循环操作**。
2. **空间局部性** ：一旦程序**访问了某个存储单元**，在不久之后，**其附近的存储单元也将被访问**，即**程序在一段时间内所访问的地址，可能集中在一定的范围之内**，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以**向量、数组、表等形式簇聚存储的**。

时间局部性是通过**将近来使用的指令和数据保存到高速缓存存储器**中，并使用高速缓存的层次结构实现。空间局部性通常是使用较大的高速缓存，并将**预取机制集成到高速缓存控制逻辑**中实现。虚拟内存技术实际上就是建立了 **“内存一外存”的两级存储器的结构，利用局部性原理实现髙速缓存。**常用的就都放在内存，不常用的都放在外存，而常用的由于局部性原理，会大大提高响应速度



## 14.页面置换算法

页面置换算法分类
局部：在内存中，**给每个进程分配的页面总数是不会变化的**。
全局：置换页面的**选择范围是所有可换出的物理界面**

**页面置换算法的作用?常见的页面置换算法有哪些?**

地址映射过程中，若在页面中**发现所要访问的页面不在内存中，则发生缺页中断** 。当发生缺页中断时，如果当前内存中并没有空闲的页面，操作系统就必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。用来选择淘汰哪一页的规则叫做页面置换算法，我们可以把页面置换算法看成是淘汰页面的规则。

- **OPT 页面置换算法（最佳页面置换算法）** ：最佳(Optimal, OPT)置换算法所选择的**被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面**,这样可以**保证获得最低的缺页率**。但由于人们目前**无法预知进程在内存下的若千页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现**。一般作为衡量其他置换算法的方法。

- **FIFO（First In First Out） 页面置换算法（先进先出页面置换算法）** : 总是淘汰最先进入内存的页面，即**选择在内存中驻留时间最久的页面**进行淘汰。

- **LRU （Least Recently Used）页面置换算法（最近最久未使用页面置换算法）** ：LRU算法赋予每个页面一个**访问字段**，用来**记录一个页面自上次被访问以来所经历的时间 T**，当须淘汰一个页面时，选择现有**页面中其 T 值最大**的，即最近最久未使用的页面予以淘汰。

- **LFU （Least Frequently Used）页面置换算法（最少使用页面置换算法）** : 该置换算法选择在**之前时期使用最少的页面作为淘汰页**。

- **改进型CLOCK时钟置换算法（非改进型只有使用位）**：一个修改位、一个使用位，**先找未被修改的，再找未被使用的**

  1.从未被修改的里面找到未被访问的

  2.从未被修改的里面找到被访问的

  3.从被修改的里面找到未被访问的

  4.即被访问又被修改

  非改进型又叫NRU(Not Recently Used)：OS循环扫描缓冲区，查找使用位为0的（也就是没有被访问的），同时将访问为置位1，这样扫描一圈以后都会变为1，就选出淘汰的。



全局置换算法：

工作集置换算法：

工作集W由时间t和工作集窗口大小来确定 



不在工作集当中的就换出



## 文件描述符fd

文件描述符（File descriptor）是计算机科学中的一个术语，是一个用于表述指向文件的引用的抽象化概念。

文件描述符在形式上是一个非负整数。实际上，它**是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表**。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。

## 15 select/poll/epoll

[如果这篇文章说不清epoll的本质，那就过来掐死我吧！](https://zhuanlan.zhihu.com/p/63179839)

IO multiplexing就是我们说的select，poll，epoll，有些地方也称这种IO方式为event driven IO。select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。 线程会阻塞在调用select/poll/epoll函数，由select函数去轮询监听多个I/O

![img](https://img2018.cnblogs.com/blog/1111824/201904/1111824-20190428163005173-911893845.png)

可以这样理解，

I/O多路复用和阻塞I/O的差异就是 阻塞I/O只能为一个socket服务，

而和NIO（非阻塞I/O）的区别就是非阻塞没有请代理，而是自己去应用程序自己去轮序 数据是否准备好了，这样消耗CPU资源，而I/O多路复用请了select/poll/epoll作为代理去轮序

通俗理解 I/O 以及select/poll/epoll

https://www.cnblogs.com/natian-ws/p/10785649.html





select，poll，epoll都是IO多路复用的机制。**I/O多路复用就是通过一种机制，一个进程可以监视多个描述符**，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。**但select，poll，epoll本质上都是同步I/O**，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。



## select

```java
int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);
```

select 函数监视的***文件描述符分3类，分别是writefds、readfds、和exceptfds***。调用后**select函数会阻塞，直到有描述符就绪**（有数据 可读、可写、或者有except），**或者超时**（timeout指定等待时间，如果立即返回设为null即可），函数返回。**当select函数返回后**，可以 通过**遍历fdset，来找到就绪的描述符**。

select目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。select的一 个**缺点在于单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024**，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但 是这样也会造成效率的降低。

## poll

```c
int poll (struct pollfd *fds, unsigned int nfds, int timeout);
```

不同于select使用三个位图来表示**三个fdset**的方式，**poll使用一个 pollfd的指针实现**。

```java
struct pollfd {
    int fd; /* file descriptor */
    short events; /* requested events to watch */
    short revents; /* returned events witnessed */
};
```

pollfd结构包含了***要监视的event和发生的event***，不再使用select“参数-值”传递的方式。同时，pollfd**并没有最大数量限制**（但是数量过大后性能也是会下降）。 和select函数一样，poll返回后，需要**轮询pollfd**来获取就绪的描述符。



> 从上面看，select和poll都需要在返回后，**`通过遍历文件描述符来获取已经就绪的socket`**。事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。

## epoll

epoll是在2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll**使用一个文件描述符管理多个描述符**，将**用户关系的文件描述符的事件存放到内核的一个事件表**中，这样在**用户空间和内核空间的copy只需一次**。



```c
int epoll_create(int size)；//创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；
int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);
```

**1. int epoll_create(int size);**
创建一个epoll的句柄，**size用来告诉内核这个监听的数目一共有多大**，这个参数不同于select()中的第一个参数，给出最大监听的fd+1的值，`参数size并不是限制了epoll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议`。
当创建好epoll句柄后，它就会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。

**2. int epoll_ctl(int epfd, int op, int fd, struct epoll_event \*event)；**
函数是对指定**描述符fd执行op操作**。
\- epfd：是epoll_create()的返回值。
\- op：表示op操作，用三个宏来表示：添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MOD。分别添加、删除和修改对fd的监听事件。
\- fd：是需要监听的fd（文件描述符）
\- epoll_event：是告诉内核需要监听什么事，struct epoll_event结构如下：

```java
struct epoll_event {
  __uint32_t events;  /* Epoll events */
  epoll_data_t data;  /* User data variable */
};

//events可以是以下几个宏的集合：
EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）；
EPOLLOUT：表示对应的文件描述符可以写；
EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）；
EPOLLERR：表示对应的文件描述符发生错误；
EPOLLHUP：表示对应的文件描述符被挂断；
EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。
EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里
```

**3. int epoll_wait(int epfd, struct epoll_event \* events, int maxevents, int timeout);**
等待epfd上的io事件，最多返回maxevents个事件。
参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。

### 二 工作模式

　epoll对文件描述符的操作有两种模式：**LT（level trigger）**和**ET（edge trigger）**。LT模式是默认模式，LT模式与ET模式的区别如下：
　　**LT模式**：当epoll_wait检测到**描述符事件发生并将此事件通知应用程序**，`应用程序可以不立即处理该事件`。**下次调用epoll_wait**时，会**再次响应应用程序并通知此事件**。
　　**ET模式**：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，`应用程序必须立即处理该事件`。如果**不处理，下次调用epoll_wait时，不会再次响应**应用程序并通知此事件。



ET模式效率更高

### epoll总结

在 select/poll中，**进程只有在调用一定的方法后，**内核才对所有监视的文件描述符进行扫描，而**epoll事先通过epoll_ctl()来注册一 个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait() 时便得到通知**。(`此处去掉了遍历文件描述符，而是通过监听回调的的机制`。这正是epoll的魅力所在。)

**epoll的优点主要是一下几个方面：**

1.**监视的描述符数量不受限制，它所支持的FD上限是最大可以打开文件的数目**，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左 右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。select的最大缺点就是进程打开的fd是有数量限制的。这对 于连接数量比较大的服务器来说根本不能满足。

2.IO效率不会随着监视fd的数量的增长而下降，epoll不同于select和poll轮询的方式，而是通过**每个fd定义的回调函数来实现的。只有就绪的fd才会执行回调函数**。

> 如果没有大量的idle -connection或者dead-connection，epoll的效率并不会比select/poll高很多，但是当遇到大量的idle- connection，就会发现epoll的效率大大高于select/poll。





## 16.操作系统中用户态和内核态的区别？

两种状态之间的转换

用户态—>内核态：

a. 系统调用

这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作，比如前例中fork()实际上就是执行了一个创建新进程的系统调用。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。

b. 异常

当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。

c. 外围设备的中断

当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。

这3种方式是系统在运行时由用户态转到内核态的最主要方式，其中系统调用可以认为是用户进程主动发起的，异常和外围设备中断则是被动的。

内核态—>用户态：设置程序状态字PSW







内核态与用户态是操作系统的两种运行级别，当程序运行在3级特权级上时，就可以称之为运行在用户态。因为这是最低特权级，是普通的用户进程运行的特权级，大部分用户直接面对的程序都是运行在用户态；

当程序运行在0级特权级上时，就可以称之为运行在内核态。

运行在用户态下的程序不能直接访问操作系统内核数据结构和程序。当我们在系统中执行一个程序时，大部分时间是运行在用户态下的，在其需要操作系统帮助完成某些它没有权力和能力完成的工作时就会切换到内核态（比如操作硬件）。

这两种状态的主要差别是

- 处于用户态执行时，进程所能访问的内存空间和对象受到限制，其所处于占有的处理器是可被抢占的，只能执行非特权指令
- 处于内核态执行时，则能访问所有的内存空间和对象，且所占有的处理器是不允许被抢占的。能执行特权指令



## 为什么用户态切换到内核态消耗时间？

因为要保存执行情况，还需要做额外检查





# Socket

## 1.什么是socket？

socket 被翻译为“套接字”，它是计算机之间进行**通信**的**一种约定**或一种方式。通过 socket 这种约定，一台计算机可以接收其他计算机的数据，也可以向其他计算机发送数据
 　socket起源于Unix，而Unix/Linux基本哲学之一就是“一切皆文件”，都可以用“打开open –> 读写write/read –> 关闭close”模式来操作。
 　我的理解就是Socket就是该模式的一个实现：即**socket是一种特殊的文件，一些socket函数就是对其进行的操作（读/写IO、打开、关闭）。**
 　Socket()函数返回一个整型的Socket描述符，随后的连接建立、数据传输等操作都是通过该Socket实现的。







## 3.基于TCP协议的Socket程序函数调用过程？

1.TCP的服务端要先**监听一个端口**，一般是**先调用bind函数**，给这个Socket赋予一个**IP地址和端口**。

2.当服务端**有了IP和端口号**，就可以**调用listen函数**进行监听。在TCP的状态图里面，有一个**listen状态**，当调用这个函数之后，服务端就进入了这个状态，这个时候客户端就可以发起连接了,告诉内核设置连接队列的长度。内核为每一个listen状态的套接字设置两个队列，未完成连接队列和已完成连接队列，这两个队列共用listen设置的连接长度。

在内核中，**为每个Socket维护两个队列**。一个是**已经建立了连接的队列**，这时候**连接三次握手已经完毕**，处于**established状态**；一个是**还没有完全建立连接**的队列，这个时候**三次握手还没完成**，处于**syn_rcvd**的状态。



3.接下来，服务端调用**accept**函数，拿出一个已经完成的连接进行处理。如果还没有完成，就要等着。

4.在服务端等待的时候，客户端可以通过**connect函数**发起连接。先在参数中指明要连接的**IP地址和端口号**，然后开始发起**三次握手**。内核会给客户端分配一个临时的端口。一旦握手成功，服务端的**accept就会返回另一个Socket**。

监听的Socket和真正用来传数据的Socket是两个，一个叫作**监听Socket**，一个叫作**已连接Socket。**

连接建立成功之后，双方开始通过read和write函数来读写数据，就像往一个文件流里面写东西一样。

这个图就是基于TCP协议的Socket程序函数调用过程:

![image-20210302113736096](E:\typora-user-images\image-20210302113736096.png)

# connect accept listen 与三次握手的关系



## 4.基于UDP协议的Socket程序函数调用过程

对于UDP来讲，过程有些不一样。UDP是没有连接的，所以不需要三次握手，也就不需要调用listen和connect，但是，UDP的的交互仍然需要IP和端口号，因而也需要bind

UDP是没有维护连接状态的，因而不需要每对连接建立一组Socket，而是只要有一个Socket，就能够和多个客户端通信。也正是因为没有连接状态，每次通信的时候，都调用sendto和recvfrom，都可以传入IP地址和端口。

![img](https://segmentfault.com/img/remote/1460000021144383)



https://github.com/CyC2018/CS-Notes/blob/master/notes/Socket.md







socket编程 见 JavaSenior





# Linux问题：

## 1.CPU资源占用率过高你会怎么办？

\1. 使用top命令定位异常进程。可以看见12836的CPU和内存占用率都非常高

![img](https://img-blog.csdn.net/20160503111524410?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

此时可以再执行ps -ef | grep java，查看所有的java进程，在结果中找到进程号为12836的进程，即可查看是哪个应用占用的该进程。

\2. 使用top -H -p 进程号  查看异常线程

![img](https://img-blog.csdn.net/20160503111715099?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

\3. 使用printf "%x\n" 线程号将异常线程号转化为16进制

![img](https://img-blog.csdn.net/20160503112248412?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

\4. 使用jstack 进程号|grep 16进制异常线程号 -A90来定位异常代码的位置（最后的-A90是日志行数，也可以输出为文本文件或使用其他数字）。可以看到异常代码的位置。

![img](https://img-blog.csdn.net/20160503112227975?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)



2.显示开机信息的指令

显示开机信息：

**dmesg**





## 16.内核态和用户态的区别

内核态：cpu可以访问内存的所有数据，包括外围设备，例如硬盘，网卡，cpu也可以将自己从一个程序切换到另一个程序。 可以执行特权指令

用户态：只能受限的访问内存，且不允许访问外围设备，占用cpu的能力被剥夺，cpu资源可以被其他程序获取。费特权指令

 

为什么要有用户态和内核态？

由于需要**限制不同的程序之间的访问能力, 防止他们获取别的程序的内存数据, 或者获取外围设备的数据**, 并发送到网络, CPU划分出两个权限等级 -- 用户态和内核态。比如分配物理内存，从父进程拷贝相关信息，拷贝设置页目录页表等等，这些显然不能随便让哪个程序就能去做，于是就自然引出特权级别的概念，显然，最关键性的权力必须由高特权级的程序来执行，这样才可以做到集中管理，减少有限资源的访问和使用冲突。

用户态和内核态的转换

1）用户态切换到内核态的3种方式

a. 系统调用

这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作，比如前例中fork()实际上就是执行了一个创建新进程的系统调用。而系统调用的机制其**核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。**

b. 异常

当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。

c. 外围设备的中断

当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。

这3种方式是系统在运行时由用户态转到内核态的最主要方式，其中**系统调用可以认为是用户进程主动发起的，异常和外围设备中断则是被动的**。





## 17.**僵尸进程、孤儿进程是因为什么原因产生的？**

## 17.1什么是孤儿进程？父进程先挂了 子进程就成为孤儿了，交给init去接管

父进程先于子进程结束，则子进程成为孤儿进程。父进程结束后，子进程的父进程由init进程接替。

## 17.2什么是僵尸进程？子进程结束了，但是父进程没有调用wait或者waitpid，去回收他的进程残留资源（PCB）

子进程结束，**而父进程并没有调用wait或waitpid获取子进程的状态信息**，子进程残留资源（PCB）存放于内核中，变成僵尸进程。

## **17.3僵尸进程过多会带来什么问题？**进程号被一直占用

如果***进程不调用wait()或waitpid()的话，那么保留的信息就不会释放***，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程. 此即为僵尸进程的危害，应当避免。

僵尸进程危害场景以及解决方案：

外部解决：kill掉父进程，使僵尸进程变为孤儿进程。会被init进程收留

　　例如有个进程，它定期的产 生一个子进程，这个子进程需要做的事情很少，做完它该做的事情之后就退出了，因此这个子进程的生命周期很短，但是，父进程只管生成新的子进程，至于子进程 退出之后的事情，则一概不闻不问，这样，系统运行上一段时间之后，系统中就会存在很多的僵死进程，倘若用ps命令查看的话，就会看到很多状态为Z的进程。 严格地来说，僵死进程并不是问题的根源，罪魁祸首是产生出大量僵死进程的那个父进程。因此，当我们寻求如何消灭系统中大量的僵死进程时，答案就是把产生大 量僵死进程的那个元凶枪毙掉（也就是通过kill发送SIGTERM或者SIGKILL信号啦）。枪毙了元凶进程之后，它产生的僵死进程就变成了孤儿进 程，这些孤儿进程会被init进程接管，**init进程会wait()这些孤儿进程**，释放它们占用的系统进程表中的资源，这样，这些已经僵死的孤儿进程 就能瞑目而去了。

内部解决（让父进程去处理）：

 1、父进程处理SIGCHLD信号，在信号处理函数中调用wait处理僵尸进程。
  2、fork两次：借助一个中间进程，父进程只wait中间进程，让中间进程再fork出孙进程。孙进程结束后会变成僵尸进程，等中间进程一结束，孙进程就成孤儿进程了

孤儿进程对系统的影响：
孤儿进程并不会有什么危害，init进程会接管并处理掉它。





## 18.Linux下，线程挂了，会导致进程崩溃吗？

答案是不一定，取决于线程操作。

1.进程（主线程）创建了多个线程，多个子线程均拥有自己独立的栈空间（存储函数参数、局部变量等），但是多个子线程和主线程共享堆、全局变量等非栈内存。

2.如果子线程的崩溃是由于自己的一亩三分地引起的，那就不会对主线程和其他子线程产生影响，但是如果子线程的崩溃是因为对共享区域造成了破坏，那么大家就一起崩溃了。

3.举个栗子：主线程是一节车厢的乘务员，诸多乘客（也就是子线程）就是经过乘务员（主线程）检票确定可以进入车厢的，也就是主线程创建了诸多子线程，每个子线程有自己独立的区域（座位啊啥的），但是诸多乘客和乘务员共享走廊啊卫生间啊等等，如果其中一名乘客座位坏了，摔了（可以认为奔溃了），那么其他乘客和乘务员都不受影响，但是如果乘客将卫生间给破坏了，他也无法使用卫生间（崩溃了），其他乘客和乘务员也不能用卫生间，好吧，那么大家一起憋着吧（崩溃了）。

多个线程**共享同一个地址的内存地址**，但是他有自己**独立的线程空间**。如果挂掉的线程在临死之前，修改了内存地址，导致地址失效或异常，那么他死后，其他线程去访问被他所修改的地址时，进程会崩溃。如果说挂掉的线程活着的时候，压根儿不会修改内存数据或地址，只是单纯的做些体力活。那么他死后，不会影响到当前进程。







## 19.为什么要有OS内核？

![image-20210908231714248](D:\Typora图片\image-20210908231714248.png)





**什么是 DMA**

DMA 的中文名称是直接内存访问，它意味着 **CPU 授予 I/O 模块权限在不涉及 CPU 的情况下读取或写入内存**。也就是 DMA 可以不需要 CPU 的参与。这个过程由称为 **DMA 控制器（DMAC）的芯片管理**。由于 DMA 设备可以直接在内存之间传输数据，而不是使用 CPU 作为中介，因此可以缓解总线上的拥塞。DMA 通过允许 CPU 执行任务，同时 DMA 系统通过系统和内存总线传输数据来提高系统并发性。



## **DMA的基本定义**

DMA，全称Direct Memory Access，即直接内存访问。

DMA传输将数据从一个地址空间复制到另一个地址空间，提供在外设和存储器之间或者存储器和存储器之间的高速数据传输。当CPU初始化这个传输动作，传输动作本身是由DMA控制器来实现和完成的。**DMA传输方式无需CPU直接控制传输，也没有中断处理方式那样保留现场和恢复现场过程，通过硬件为RAM和IO设备开辟一条直接传输数据的通道，使得CPU的效率大大提高**。





**RAID 的不同级别**

RAID 称为 磁盘冗余阵列，简称 磁盘阵列。利用虚拟化技术把多个硬盘结合在一起，成为一个或多个磁盘阵列组，目的是提升性能或数据冗余。

RAID 有不同的级别

> - RAID 0 - 无容错的条带化磁盘阵列
> - RAID 1 - 镜像和双工
> - RAID 2 - 内存式纠错码
> - RAID 3 - 比特交错奇偶校验
> - RAID 4 - 块交错奇偶校验
> - RAID 5 - 块交错分布式奇偶校验
> - RAID 6 - P + Q 冗余







